{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_noisy = r'Input_Patches_3Dreal1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_noisy, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)\n",
    "data= torch.from_numpy(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 12\n",
    "w2 = 12\n",
    "w3 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10067, 1728])\n",
      "torch.Size([2517, 1728])\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "vaild = data[train_size:]\n",
    "print(train.shape)\n",
    "print(vaild.shape)\n",
    "batch_size1 = 64\n",
    "w1 = 12\n",
    "w2 = 12\n",
    "w3 = 12\n",
    "train_data= TensorDataset(train)\n",
    "vaild_data= TensorDataset(vaild)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size = 64,\n",
    "                                           shuffle = True)\n",
    "\n",
    "vaild_loader = torch.utils.data.DataLoader(vaild_data,\n",
    "                                          batch_size = 64,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully connected (FC) block\n",
    "class FCB(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.bn = nn.BatchNorm1d(output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAB(nn.Module):  ##position attention block\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fcb1 = FCB(input_size, output_size, dropout)\n",
    "        self.fcb2 = FCB(input_size, output_size, dropout)\n",
    "        self.fcb3 = FCB(input_size, output_size, dropout)\n",
    "        self.fcb4 = FCB(input_size, output_size, dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.fcb1(x)\n",
    "        x2 = self.fcb2(x)\n",
    "        x3 = self.fcb3(x)\n",
    "        x4 = self.fcb4(x)\n",
    "        \n",
    "\n",
    "        x = x1*x2\n",
    "        x = self.softmax(x)\n",
    "        x = x*x3\n",
    "        x = x+x4\n",
    "        \n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cov1d = nn.Conv1d(in_channels=1, out_channels= 64 ,kernel_size = 5, padding=0, stride=1)\n",
    "\n",
    "        self.pab1 = PAB(int(input_size-5+1), 128, dropout)\n",
    "        self.fcb1 = FCB(128, 128, dropout)\n",
    "\n",
    "        self.pab2 = PAB(128, 64, dropout)\n",
    "        self.fcb2 = FCB(64, 64, dropout)\n",
    "\n",
    "        self.pab3 = PAB(64, 32, dropout)\n",
    "        self.fcb3 = FCB(32, 32, dropout)\n",
    "\n",
    "        self.pab4 = PAB(32, 16, dropout)\n",
    "        self.fcb4 = FCB(16, 16, dropout)\n",
    "\n",
    "        self.pab5 = PAB(16, 8, dropout)\n",
    "        self.fcb5 = FCB(8, 8, dropout)\n",
    "\n",
    "        self.pab6 = PAB(8, 4, dropout)\n",
    "        self.fcb6 = FCB(4, 4, dropout)\n",
    "        \n",
    "        self.fcb7 = FCB(4, 4, dropout)\n",
    "        self.pab7 = PAB(4, 4, dropout)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1])\n",
    "        x = self.cov1d(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = nn.AdaptiveAvgPool1d(1)(x)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x1 = self.pab1(x)\n",
    "        x13 = self.fcb1(x1)\n",
    "\n",
    "        x2 = self.pab2(x1)\n",
    "        x12 = self.fcb2(x2)\n",
    "\n",
    "        x3 = self.pab3(x2)\n",
    "        x11 = self.fcb3(x3)\n",
    "\n",
    "        x4 = self.pab4(x3)\n",
    "        x10 = self.fcb4(x4)\n",
    "\n",
    "        x5 = self.pab5(x4)\n",
    "        x9 = self.fcb5(x5)\n",
    "\n",
    "        x6 = self.pab6(x5)\n",
    "        x8 = self.fcb6(x6)\n",
    "\n",
    "        x7 = self.fcb7(x6)\n",
    "        x7 = self.pab7(x7)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        return x7,x8,x9,x10,x11,x12,x13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomActivation(torch.autograd.Function):    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        y = 7/3 * (x - torch.tanh(x)) * torch.cos(x/2)\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        grad_x = grad_output * (7/3 * ((torch.cos(x/2)*(1 - torch.pow(torch.cosh(x), -2)))+ (x - torch.tanh(x))*(-0.5*torch.sin(x/2))))\n",
    "                                       \n",
    "        return grad_x\n",
    "    \n",
    "class CustomActivationModule(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return CustomActivation.apply(x)  \n",
    "    \n",
    "\n",
    "activation = CustomActivationModule()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pab1 = PAB(8, 8, dropout)\n",
    "        self.pab2 = PAB(16, 16, dropout)\n",
    "        self.pab3 = PAB(32, 32, dropout)\n",
    "        self.pab4 = PAB(64, 64, dropout)\n",
    "        self.pab5 = PAB(128, 128, dropout)\n",
    "\n",
    "        self.fc = nn.Linear(256,output_size)\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "    def forward(self, x7,x8,x9,x10,x11,x12,x13):\n",
    "        \n",
    "        x = torch.cat((x7,x8),dim=1)\n",
    "        x = self.pab1(x)\n",
    "        x = torch.cat((x,x9),dim=1)\n",
    "        x = self.pab2(x)\n",
    "        x = torch.cat((x,x10),dim=1)\n",
    "        x = self.pab3(x)\n",
    "        x = torch.cat((x,x11),dim=1)\n",
    "        x = self.pab4(x)\n",
    "        x = torch.cat((x,x12),dim=1)\n",
    "        x = self.pab5(x)\n",
    "        x = torch.cat((x,x13),dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size)\n",
    "        self.decoder = Decoder(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x7,x8,x9,x10,x11,x12,x13= self.encoder(x)\n",
    "        x = self.decoder(x7,x8,x9,x10,x11,x12,x13)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WelschLoss(nn.Module):\n",
    "    def __init__(self, delta):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        x = y_true - y_pred\n",
    "        loss = 1 - torch.exp(-0.5 * torch.pow((x / self.delta),2))\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self,delta,r):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.r = r\n",
    "    def forward(self,input,output):\n",
    "        N = input-output\n",
    "        temp = output*N\n",
    "        temp1 = data.shape[1]*(temp.sum(1))\n",
    "        temp2 = (output.sum(1))*(N.sum(1))\n",
    "        temp3 = torch.pow(data.shape[1]*((output**2).sum(1)) - ((output.sum(1))**2),1/2)\n",
    "        temp4 = torch.pow(data.shape[1]*((N**2).sum(1))-((N.sum(1))**2),1/2) \n",
    "        loss = (temp1-temp2)/(temp3*temp4)\n",
    "        a = torch.min(loss)\n",
    "        b = torch.mean(1 - torch.exp(-0.5 * torch.pow((N / self.delta),2)))        \n",
    "        return self.r*a+(1-self.r)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss0(nn.Module):\n",
    "    def __init__(self,delta,r):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.r = r\n",
    "    def forward(self,input,output):\n",
    "        N = input-output\n",
    "        b = torch.mean(1 - torch.exp(-0.5 * torch.pow((N / self.delta),2)))\n",
    "        K = output.shape[0]\n",
    "        y2_mean = torch.mean(output)\n",
    "        n2_mean = torch.mean(N)\n",
    "        covariance = 0.0\n",
    "        variance_y2 = 0.0\n",
    "        variance_n2 = 0.0\n",
    "        for j in range(K):\n",
    "            y2_sample = output[j, :]\n",
    "            n2_sample = N[j, :]\n",
    "            covariance += ((y2_sample - y2_mean) * (n2_sample - n2_mean))\n",
    "            variance_y2 += ((y2_sample - y2_mean) ** 2)\n",
    "            variance_n2 += ((n2_sample - n2_mean) ** 2)\n",
    "            lcc_value = (covariance / torch.sqrt(variance_y2 * variance_n2)) ** 2\n",
    "            lcc_value = torch.mean(lcc_value)\n",
    "        return self.r*lcc_value+(1-self.r)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "model = AutoEncoder(w1*w2*w3,w1*w2*w3).to(device)\n",
    "criterion = Loss0(delta=0.55,r=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.3229, Valid Loss: 0.2671\n",
      "loss_train:  [0.3229213319247282]\n",
      "vaild_train:  [0.2671116329729557]\n",
      "Epoch [2/100], Train Loss: 0.2489, Valid Loss: 0.2352\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564]\n",
      "Epoch [3/100], Train Loss: 0.2285, Valid Loss: 0.2224\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713]\n",
      "Epoch [4/100], Train Loss: 0.2181, Valid Loss: 0.2138\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253]\n",
      "Epoch [5/100], Train Loss: 0.2111, Valid Loss: 0.2074\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045]\n",
      "Epoch [6/100], Train Loss: 0.2065, Valid Loss: 0.2059\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327]\n",
      "Epoch [7/100], Train Loss: 0.2041, Valid Loss: 0.2045\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364]\n",
      "Epoch [8/100], Train Loss: 0.2022, Valid Loss: 0.2011\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825]\n",
      "Epoch [9/100], Train Loss: 0.2005, Valid Loss: 0.2016\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206]\n",
      "Epoch [10/100], Train Loss: 0.1996, Valid Loss: 0.1989\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397]\n",
      "Epoch [11/100], Train Loss: 0.1991, Valid Loss: 0.1993\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124]\n",
      "Epoch [12/100], Train Loss: 0.1979, Valid Loss: 0.1989\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664]\n",
      "Epoch [13/100], Train Loss: 0.1970, Valid Loss: 0.1990\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046]\n",
      "Epoch [14/100], Train Loss: 0.1958, Valid Loss: 0.1971\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962]\n",
      "Epoch [15/100], Train Loss: 0.1959, Valid Loss: 0.1972\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865]\n",
      "Epoch [16/100], Train Loss: 0.1954, Valid Loss: 0.1969\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362]\n",
      "Epoch [17/100], Train Loss: 0.1944, Valid Loss: 0.1963\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346]\n",
      "Epoch [18/100], Train Loss: 0.1943, Valid Loss: 0.1959\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815]\n",
      "Epoch [19/100], Train Loss: 0.1939, Valid Loss: 0.1955\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922]\n",
      "Epoch [20/100], Train Loss: 0.1933, Valid Loss: 0.1955\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674]\n",
      "Epoch [21/100], Train Loss: 0.1929, Valid Loss: 0.1948\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952]\n",
      "Epoch [22/100], Train Loss: 0.1928, Valid Loss: 0.1951\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518]\n",
      "Epoch [23/100], Train Loss: 0.1924, Valid Loss: 0.1942\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417]\n",
      "Epoch [24/100], Train Loss: 0.1918, Valid Loss: 0.1933\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076]\n",
      "Epoch [25/100], Train Loss: 0.1918, Valid Loss: 0.1929\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054]\n",
      "Epoch [26/100], Train Loss: 0.1914, Valid Loss: 0.1925\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007]\n",
      "Epoch [27/100], Train Loss: 0.1910, Valid Loss: 0.1924\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456]\n",
      "Epoch [28/100], Train Loss: 0.1912, Valid Loss: 0.1920\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734]\n",
      "Epoch [29/100], Train Loss: 0.1908, Valid Loss: 0.1928\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506]\n",
      "Epoch [30/100], Train Loss: 0.1904, Valid Loss: 0.1924\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584]\n",
      "Epoch [31/100], Train Loss: 0.1904, Valid Loss: 0.1922\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946]\n",
      "Epoch [32/100], Train Loss: 0.1896, Valid Loss: 0.1942\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954]\n",
      "Epoch [33/100], Train Loss: 0.1901, Valid Loss: 0.1918\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548]\n",
      "Epoch [34/100], Train Loss: 0.1896, Valid Loss: 0.1914\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896]\n",
      "Epoch [35/100], Train Loss: 0.1895, Valid Loss: 0.1921\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446]\n",
      "Epoch [36/100], Train Loss: 0.1893, Valid Loss: 0.1911\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205]\n",
      "Epoch [37/100], Train Loss: 0.1890, Valid Loss: 0.1915\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278]\n",
      "Epoch [38/100], Train Loss: 0.1889, Valid Loss: 0.1906\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521]\n",
      "Epoch [39/100], Train Loss: 0.1886, Valid Loss: 0.1895\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804]\n",
      "Epoch [40/100], Train Loss: 0.1884, Valid Loss: 0.1902\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739, 0.18843699095747138]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804, 0.19018017426133155]\n",
      "Epoch [41/100], Train Loss: 0.1883, Valid Loss: 0.1889\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739, 0.18843699095747138, 0.18831351380559463]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804, 0.19018017426133155, 0.1888642393052578]\n",
      "Epoch [42/100], Train Loss: 0.1885, Valid Loss: 0.1894\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739, 0.18843699095747138, 0.18831351380559463, 0.1884695741383335]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804, 0.19018017426133155, 0.1888642393052578, 0.1893871795386076]\n",
      "Epoch [43/100], Train Loss: 0.1881, Valid Loss: 0.1905\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739, 0.18843699095747138, 0.18831351380559463, 0.1884695741383335, 0.18812626524816586]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804, 0.19018017426133155, 0.1888642393052578, 0.1893871795386076, 0.1905200310051441]\n",
      "Epoch [44/100], Train Loss: 0.1879, Valid Loss: 0.1904\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739, 0.18843699095747138, 0.18831351380559463, 0.1884695741383335, 0.18812626524816586, 0.18791660053443304]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804, 0.19018017426133155, 0.1888642393052578, 0.1893871795386076, 0.1905200310051441, 0.19044201262295246]\n",
      "Epoch [45/100], Train Loss: 0.1872, Valid Loss: 0.1897\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739, 0.18843699095747138, 0.18831351380559463, 0.1884695741383335, 0.18812626524816586, 0.18791660053443304, 0.1872460480920876]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804, 0.19018017426133155, 0.1888642393052578, 0.1893871795386076, 0.1905200310051441, 0.19044201262295246, 0.1896635815501213]\n",
      "Epoch [46/100], Train Loss: 0.1871, Valid Loss: 0.1899\n",
      "loss_train:  [0.3229213319247282, 0.24886217128626908, 0.2285256548018395, 0.21812612733131723, 0.21105555218609073, 0.2064709922746767, 0.20414828254452236, 0.20218351766278472, 0.20047465117671823, 0.1996144526932813, 0.19908777577213094, 0.1979492102054101, 0.19695993239366555, 0.1958295970777922, 0.19588743404874318, 0.19538644654086873, 0.19441634463735774, 0.19427686571320402, 0.19386389606361148, 0.1932545105301881, 0.19286019524818734, 0.19283476481332054, 0.19237886529557313, 0.19178226939107798, 0.1917503028164936, 0.19144897681625583, 0.1909656719882277, 0.19118531519853615, 0.19082910152553004, 0.19041101257257823, 0.19037519782027112, 0.18963345027045359, 0.19012514926210233, 0.18964270832417887, 0.189460481835317, 0.18928746850807457, 0.1890193711541876, 0.1888685301889347, 0.1885793004420739, 0.18843699095747138, 0.18831351380559463, 0.1884695741383335, 0.18812626524816586, 0.18791660053443304, 0.1872460480920876, 0.18714770297460917]\n",
      "vaild_train:  [0.2671116329729557, 0.23518313094973564, 0.22238983139395713, 0.2137930255383253, 0.20742773450911045, 0.20587327033281327, 0.20450627468526364, 0.20108375772833825, 0.2015613093972206, 0.19888899736106397, 0.19931192845106124, 0.19893740974366664, 0.1989709097892046, 0.1970689047127962, 0.19721137546002865, 0.1968798704445362, 0.1963215846568346, 0.19589164927601815, 0.19552318006753922, 0.19554159715771674, 0.19475897140800952, 0.19507274255156518, 0.19419703148305417, 0.1933288026601076, 0.19288317002356054, 0.19245754070580007, 0.19243786334991456, 0.191988430544734, 0.19278097711503506, 0.1924470353871584, 0.19215838611125946, 0.19420860670506954, 0.1917575180530548, 0.1913670025765896, 0.19208033829927446, 0.1911385130137205, 0.19150736108422278, 0.1905746005475521, 0.18950977958738804, 0.19018017426133155, 0.1888642393052578, 0.1893871795386076, 0.1905200310051441, 0.19044201262295246, 0.1896635815501213, 0.18988638892769813]\n",
      "Epoch [47/100], Train Loss: 0.1873, Valid Loss: 0.1899\n",
      "Early stopped at epoch 46, train loss stop improving\n",
      "Training finished\n",
      "472.8350830078125\n"
     ]
    }
   ],
   "source": [
    "loss_0 = []\n",
    "start_time = time.time()\n",
    "es_cnt = 0\n",
    "es_thres = 5\n",
    "prev_train_loss = float('inf')\n",
    "loss_train = []\n",
    "loss_vaild = []\n",
    "num_epochs = 100 \n",
    "for epoch in range(num_epochs):\n",
    "  train_loss = 0.0\n",
    "  \n",
    "  for i , (batch) in enumerate(train_loader):\n",
    "\n",
    "    train_batch = batch[0].to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_batch)\n",
    "    loss = criterion(outputs, train_batch)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    loss_0.append(loss.item())\n",
    "\n",
    "    train_loss += loss.item()\n",
    "  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "  loss_train.append(train_loss)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  valid_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for i , (batch) in enumerate(vaild_loader):\n",
    "    \n",
    "      val_batch = batch[0].to(device)\n",
    "      \n",
    "      outputs = model(val_batch)\n",
    "      loss = criterion(outputs, val_batch)\n",
    "      valid_loss += loss.item()\n",
    "    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "    loss_vaild.append(valid_loss)\n",
    "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "\n",
    "    \n",
    "    # Early stopping\n",
    "    if train_loss - prev_train_loss >= 0:\n",
    "        es_cnt += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if es_cnt >= es_thres:\n",
    "        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "        break  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    prev_train_loss = train_loss\n",
    "  print('loss_train: ', loss_train)\n",
    "  print('vaild_train: ',loss_vaild)          \n",
    "print(\"Training finished\")\n",
    "current_time = time.time()\n",
    "time_sum = current_time-start_time\n",
    "print(time_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = pd.DataFrame(loss_train)\n",
    "loss_vaild = pd.DataFrame(loss_vaild)\n",
    "loss = pd.concat([loss_train,loss_vaild],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to_csv(r'loss_3dreal1.csv',index=False)\n",
    "torch.save(model.state_dict(), r'.\\model_3dreal1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12584, 1728])\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(w1*w2*w3,w1*w2*w3).to(device)\n",
    "data = data.to(device)\n",
    "model.load_state_dict(torch.load(r'.\\model_3dreal1.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "    loss = criterion(output, data)\n",
    "print(output.shape)\n",
    "\n",
    "output = output.cpu()\n",
    "output = output.numpy()\n",
    "output = pd.DataFrame(output)\n",
    "output.to_csv(r'./output_3dreal1.csv',index=None,header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
