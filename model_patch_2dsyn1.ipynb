{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import tushare as ts\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_noisy = r'Input_Patches_2Dsyn1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_noisy, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.285655</td>\n",
       "      <td>-0.094759</td>\n",
       "      <td>0.059033</td>\n",
       "      <td>0.082095</td>\n",
       "      <td>-0.169731</td>\n",
       "      <td>-0.141456</td>\n",
       "      <td>-0.065269</td>\n",
       "      <td>-0.101775</td>\n",
       "      <td>-0.305867</td>\n",
       "      <td>0.142491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>-0.494745</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>0.054619</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.328060</td>\n",
       "      <td>-0.203638</td>\n",
       "      <td>-0.329366</td>\n",
       "      <td>0.017071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.034454</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>-0.350245</td>\n",
       "      <td>0.085406</td>\n",
       "      <td>0.066838</td>\n",
       "      <td>0.103323</td>\n",
       "      <td>0.183920</td>\n",
       "      <td>0.196916</td>\n",
       "      <td>0.400856</td>\n",
       "      <td>-0.097729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083210</td>\n",
       "      <td>-0.213278</td>\n",
       "      <td>0.398580</td>\n",
       "      <td>0.199259</td>\n",
       "      <td>0.193139</td>\n",
       "      <td>-0.182990</td>\n",
       "      <td>-0.151285</td>\n",
       "      <td>0.054522</td>\n",
       "      <td>0.065290</td>\n",
       "      <td>0.144964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.079837</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>-0.157144</td>\n",
       "      <td>-0.011358</td>\n",
       "      <td>0.043089</td>\n",
       "      <td>-0.154546</td>\n",
       "      <td>-0.025915</td>\n",
       "      <td>0.608872</td>\n",
       "      <td>0.222907</td>\n",
       "      <td>-0.214785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482898</td>\n",
       "      <td>0.356052</td>\n",
       "      <td>-0.223782</td>\n",
       "      <td>-0.116979</td>\n",
       "      <td>0.066285</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.052318</td>\n",
       "      <td>-0.062070</td>\n",
       "      <td>-0.075138</td>\n",
       "      <td>0.269355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239533</td>\n",
       "      <td>-0.248196</td>\n",
       "      <td>0.082898</td>\n",
       "      <td>-0.101518</td>\n",
       "      <td>0.311064</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.091698</td>\n",
       "      <td>0.111151</td>\n",
       "      <td>-0.051184</td>\n",
       "      <td>-0.204132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314867</td>\n",
       "      <td>-0.242084</td>\n",
       "      <td>-0.071824</td>\n",
       "      <td>-0.056087</td>\n",
       "      <td>0.134982</td>\n",
       "      <td>0.389893</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>-0.232038</td>\n",
       "      <td>0.160488</td>\n",
       "      <td>0.108543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.564912</td>\n",
       "      <td>0.070714</td>\n",
       "      <td>-0.004341</td>\n",
       "      <td>0.421713</td>\n",
       "      <td>-0.036241</td>\n",
       "      <td>0.892340</td>\n",
       "      <td>0.152882</td>\n",
       "      <td>0.051835</td>\n",
       "      <td>0.282456</td>\n",
       "      <td>-0.143947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282989</td>\n",
       "      <td>0.312111</td>\n",
       "      <td>0.119921</td>\n",
       "      <td>-0.299165</td>\n",
       "      <td>0.060922</td>\n",
       "      <td>0.158843</td>\n",
       "      <td>-0.100142</td>\n",
       "      <td>0.015174</td>\n",
       "      <td>0.059186</td>\n",
       "      <td>0.354470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33137</th>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.095579</td>\n",
       "      <td>0.179706</td>\n",
       "      <td>0.077812</td>\n",
       "      <td>0.106669</td>\n",
       "      <td>-0.449320</td>\n",
       "      <td>0.047308</td>\n",
       "      <td>-0.429691</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>0.050212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036615</td>\n",
       "      <td>-0.164099</td>\n",
       "      <td>-0.182914</td>\n",
       "      <td>-0.083881</td>\n",
       "      <td>0.217836</td>\n",
       "      <td>-0.162975</td>\n",
       "      <td>-0.216453</td>\n",
       "      <td>0.528084</td>\n",
       "      <td>0.151361</td>\n",
       "      <td>-0.348705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33138</th>\n",
       "      <td>-0.231164</td>\n",
       "      <td>-0.173054</td>\n",
       "      <td>-0.117294</td>\n",
       "      <td>0.149689</td>\n",
       "      <td>-0.097406</td>\n",
       "      <td>0.342493</td>\n",
       "      <td>-0.011129</td>\n",
       "      <td>-0.307579</td>\n",
       "      <td>-0.147544</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239727</td>\n",
       "      <td>0.168824</td>\n",
       "      <td>0.329842</td>\n",
       "      <td>-0.226346</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>0.353435</td>\n",
       "      <td>0.181593</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>-0.116774</td>\n",
       "      <td>-0.007252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33139</th>\n",
       "      <td>-0.078532</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>-0.073423</td>\n",
       "      <td>0.043979</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>0.102078</td>\n",
       "      <td>-0.326204</td>\n",
       "      <td>-0.343582</td>\n",
       "      <td>-0.218178</td>\n",
       "      <td>0.136061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076938</td>\n",
       "      <td>0.521511</td>\n",
       "      <td>0.112031</td>\n",
       "      <td>-0.056174</td>\n",
       "      <td>-0.225504</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>-0.083210</td>\n",
       "      <td>0.146706</td>\n",
       "      <td>0.143406</td>\n",
       "      <td>0.167758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33140</th>\n",
       "      <td>-0.231931</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>-0.168617</td>\n",
       "      <td>-0.094112</td>\n",
       "      <td>-0.081586</td>\n",
       "      <td>-0.113479</td>\n",
       "      <td>0.063115</td>\n",
       "      <td>-0.027429</td>\n",
       "      <td>-0.097478</td>\n",
       "      <td>-0.018648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258984</td>\n",
       "      <td>-0.148469</td>\n",
       "      <td>-0.149496</td>\n",
       "      <td>0.053072</td>\n",
       "      <td>-0.309760</td>\n",
       "      <td>0.048369</td>\n",
       "      <td>-0.032407</td>\n",
       "      <td>-0.070822</td>\n",
       "      <td>-0.263769</td>\n",
       "      <td>0.302118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33141</th>\n",
       "      <td>-0.070338</td>\n",
       "      <td>-0.094341</td>\n",
       "      <td>-0.125153</td>\n",
       "      <td>0.073751</td>\n",
       "      <td>-0.048972</td>\n",
       "      <td>0.380870</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.113918</td>\n",
       "      <td>0.198744</td>\n",
       "      <td>0.184822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.317294</td>\n",
       "      <td>-0.320403</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>-0.287481</td>\n",
       "      <td>-0.359201</td>\n",
       "      <td>0.089425</td>\n",
       "      <td>-0.197743</td>\n",
       "      <td>0.105451</td>\n",
       "      <td>-0.025696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33142 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0     -0.285655 -0.094759  0.059033  0.082095 -0.169731 -0.141456 -0.065269   \n",
       "1     -0.034454  0.024164 -0.350245  0.085406  0.066838  0.103323  0.183920   \n",
       "2     -0.079837 -0.129883 -0.157144 -0.011358  0.043089 -0.154546 -0.025915   \n",
       "3      0.239533 -0.248196  0.082898 -0.101518  0.311064 -0.005159  0.091698   \n",
       "4      0.564912  0.070714 -0.004341  0.421713 -0.036241  0.892340  0.152882   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "33137  0.016760  0.095579  0.179706  0.077812  0.106669 -0.449320  0.047308   \n",
       "33138 -0.231164 -0.173054 -0.117294  0.149689 -0.097406  0.342493 -0.011129   \n",
       "33139 -0.078532  0.020383 -0.073423  0.043979 -0.008138  0.102078 -0.326204   \n",
       "33140 -0.231931  0.061216 -0.168617 -0.094112 -0.081586 -0.113479  0.063115   \n",
       "33141 -0.070338 -0.094341 -0.125153  0.073751 -0.048972  0.380870  0.041785   \n",
       "\n",
       "           7         8         9     ...      2294      2295      2296  \\\n",
       "0     -0.101775 -0.305867  0.142491  ...  0.010872 -0.494745  0.326118   \n",
       "1      0.196916  0.400856 -0.097729  ... -0.083210 -0.213278  0.398580   \n",
       "2      0.608872  0.222907 -0.214785  ...  0.482898  0.356052 -0.223782   \n",
       "3      0.111151 -0.051184 -0.204132  ... -0.314867 -0.242084 -0.071824   \n",
       "4      0.051835  0.282456 -0.143947  ...  0.282989  0.312111  0.119921   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "33137 -0.429691  0.127659  0.050212  ... -0.036615 -0.164099 -0.182914   \n",
       "33138 -0.307579 -0.147544  0.015597  ... -0.239727  0.168824  0.329842   \n",
       "33139 -0.343582 -0.218178  0.136061  ... -0.076938  0.521511  0.112031   \n",
       "33140 -0.027429 -0.097478 -0.018648  ... -0.258984 -0.148469 -0.149496   \n",
       "33141  0.113918  0.198744  0.184822  ...  0.094033 -0.317294 -0.320403   \n",
       "\n",
       "           2297      2298      2299      2300      2301      2302      2303  \n",
       "0      0.023124  0.054619  0.011072  0.328060 -0.203638 -0.329366  0.017071  \n",
       "1      0.199259  0.193139 -0.182990 -0.151285  0.054522  0.065290  0.144964  \n",
       "2     -0.116979  0.066285 -0.001133 -0.052318 -0.062070 -0.075138  0.269355  \n",
       "3     -0.056087  0.134982  0.389893  0.016835 -0.232038  0.160488  0.108543  \n",
       "4     -0.299165  0.060922  0.158843 -0.100142  0.015174  0.059186  0.354470  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "33137 -0.083881  0.217836 -0.162975 -0.216453  0.528084  0.151361 -0.348705  \n",
       "33138 -0.226346  0.250965  0.353435  0.181593  0.019157 -0.116774 -0.007252  \n",
       "33139 -0.056174 -0.225504  0.015828 -0.083210  0.146706  0.143406  0.167758  \n",
       "33140  0.053072 -0.309760  0.048369 -0.032407 -0.070822 -0.263769  0.302118  \n",
       "33141 -0.067642 -0.287481 -0.359201  0.089425 -0.197743  0.105451 -0.025696  \n",
       "\n",
       "[33142 rows x 2304 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)\n",
    "data= torch.from_numpy(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33142, 2304])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26513, 2304])\n",
      "torch.Size([6629, 2304])\n"
     ]
    }
   ],
   "source": [
    "#将前80%作为训练集，后20%作为测试集\n",
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "vaild = data[train_size:]\n",
    "print(train.shape)\n",
    "print(vaild.shape)\n",
    "batch_size1 = 64\n",
    "w1 = 48\n",
    "w2 = 48\n",
    "\n",
    "train_data= TensorDataset(train)\n",
    "vaild_data= TensorDataset(vaild)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size = 64,\n",
    "                                           shuffle = True)\n",
    "\n",
    "vaild_loader = torch.utils.data.DataLoader(vaild_data,\n",
    "                                          batch_size = 64,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Fully connected (FC) block\n",
    "class FCB(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.bn = nn.BatchNorm1d(output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.fcb0 = FCB(input_size, 128, dropout)\n",
    "        self.fcb1 = FCB(128, 64, dropout)\n",
    "\n",
    "        self.fcb2 = FCB(64, 32, dropout)\n",
    "\n",
    "        self.fcb3 = FCB(32, 16, dropout)\n",
    "\n",
    "        self.fcb4 = FCB(16, 8, dropout)\n",
    "\n",
    "        self.fcb5 = FCB(8, 4, dropout)\n",
    "\n",
    "        self.fcb6 = FCB(4, 4, dropout)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = x.reshape(x.shape[0],1,x.shape[1])\n",
    "\n",
    "        x1 = self.fcb0(x)#x->128\n",
    "        x2 = self.fcb1(x1)\n",
    "\n",
    "        x3 = self.fcb2(x2)\n",
    "\n",
    "        x4 = self.fcb3(x3)\n",
    "\n",
    "        x5 = self.fcb4(x4)\n",
    "\n",
    "        x6 = self.fcb5(x5)\n",
    "\n",
    "        x7 = self.fcb6(x6)\n",
    "\n",
    "        x8 = self.fcb6(x7)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        return x2,x3,x4,x5,x6,x7,x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pab1 = FCB(8, 8, dropout)\n",
    "        self.pab2 = FCB(16, 16, dropout)\n",
    "        self.pab3 = FCB(32, 32, dropout)\n",
    "        self.pab4 = FCB(64, 64, dropout)\n",
    "        self.pab5 = FCB(128, 128, dropout)\n",
    "        self.pab6 = FCB(128, output_size, dropout)\n",
    "\n",
    "        self.activation = nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self,x2, x3,x4,x5,x6,x7,x8):\n",
    "        \n",
    "        x = torch.cat((x6,x8),dim=1)\n",
    "        x = self.pab1(x)\n",
    "        x = torch.cat((x,x5),dim=1)\n",
    "        x = self.pab2(x)\n",
    "        x = torch.cat((x,x4),dim=1)\n",
    "        x = self.pab3(x)\n",
    "        x = torch.cat((x,x3),dim=1)\n",
    "        x = self.pab4(x)\n",
    "        x = torch.cat((x,x2),dim=1)\n",
    "        x = self.pab5(x)\n",
    "        x = self.pab6(x)\n",
    "\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size)\n",
    "        self.decoder = Decoder(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2, x3,x4,x5,x6,x7,x8= self.encoder(x)\n",
    "        x = self.decoder(x2, x3,x4,x5,x6,x7,x8)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "model = AutoEncoder(w1*w2,w1*w2).to(device)\n",
    "#将模型转移到GPU上\n",
    "#criterion = MeanHuberLoss(delta=1.3)\n",
    "#criterion = WelschLoss(delta=0.5)\n",
    "#criterion = Loss0(delta=0.46,r=0.05)#0.5 and 0.2,SNR:-8dB ok\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.7753, Valid Loss: 0.4901\n",
      "loss_train:  [0.7753308021160493]\n",
      "vaild_train:  [0.490129167930438]\n",
      "Epoch [2/100], Train Loss: 0.2982, Valid Loss: 0.1916\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196]\n",
      "Epoch [3/100], Train Loss: 0.1211, Valid Loss: 0.0916\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341]\n",
      "Epoch [4/100], Train Loss: 0.0724, Valid Loss: 0.0678\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995]\n",
      "Epoch [5/100], Train Loss: 0.0635, Valid Loss: 0.0635\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188]\n",
      "Epoch [6/100], Train Loss: 0.0624, Valid Loss: 0.0628\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298]\n",
      "Epoch [7/100], Train Loss: 0.0623, Valid Loss: 0.0625\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747]\n",
      "Epoch [8/100], Train Loss: 0.0621, Valid Loss: 0.0624\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049]\n",
      "Epoch [9/100], Train Loss: 0.0620, Valid Loss: 0.0623\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419]\n",
      "Epoch [10/100], Train Loss: 0.0619, Valid Loss: 0.0621\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334]\n",
      "Epoch [11/100], Train Loss: 0.0617, Valid Loss: 0.0619\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704]\n",
      "Epoch [12/100], Train Loss: 0.0615, Valid Loss: 0.0617\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617]\n",
      "Epoch [13/100], Train Loss: 0.0614, Valid Loss: 0.0615\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686]\n",
      "Epoch [14/100], Train Loss: 0.0610, Valid Loss: 0.0613\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845]\n",
      "Epoch [15/100], Train Loss: 0.0604, Valid Loss: 0.0611\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284]\n",
      "Epoch [16/100], Train Loss: 0.0598, Valid Loss: 0.0610\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205]\n",
      "Epoch [17/100], Train Loss: 0.0594, Valid Loss: 0.0609\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583]\n",
      "Epoch [18/100], Train Loss: 0.0591, Valid Loss: 0.0608\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074]\n",
      "Epoch [19/100], Train Loss: 0.0589, Valid Loss: 0.0606\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044]\n",
      "Epoch [20/100], Train Loss: 0.0588, Valid Loss: 0.0604\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296]\n",
      "Epoch [21/100], Train Loss: 0.0587, Valid Loss: 0.0603\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245]\n",
      "Epoch [22/100], Train Loss: 0.0586, Valid Loss: 0.0602\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954]\n",
      "Epoch [23/100], Train Loss: 0.0585, Valid Loss: 0.0601\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298]\n",
      "Epoch [24/100], Train Loss: 0.0584, Valid Loss: 0.0601\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675]\n",
      "Epoch [25/100], Train Loss: 0.0583, Valid Loss: 0.0600\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809]\n",
      "Epoch [26/100], Train Loss: 0.0583, Valid Loss: 0.0600\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778]\n",
      "Epoch [27/100], Train Loss: 0.0582, Valid Loss: 0.0599\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985]\n",
      "Epoch [28/100], Train Loss: 0.0581, Valid Loss: 0.0597\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926]\n",
      "Epoch [29/100], Train Loss: 0.0580, Valid Loss: 0.0597\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388]\n",
      "Epoch [30/100], Train Loss: 0.0580, Valid Loss: 0.0597\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757]\n",
      "Epoch [31/100], Train Loss: 0.0578, Valid Loss: 0.0596\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951]\n",
      "Epoch [32/100], Train Loss: 0.0577, Valid Loss: 0.0595\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456]\n",
      "Epoch [33/100], Train Loss: 0.0576, Valid Loss: 0.0595\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497]\n",
      "Epoch [34/100], Train Loss: 0.0576, Valid Loss: 0.0595\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174]\n",
      "Epoch [35/100], Train Loss: 0.0575, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696]\n",
      "Epoch [36/100], Train Loss: 0.0575, Valid Loss: 0.0594\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006]\n",
      "Epoch [37/100], Train Loss: 0.0575, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372]\n",
      "Epoch [38/100], Train Loss: 0.0574, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829]\n",
      "Epoch [39/100], Train Loss: 0.0574, Valid Loss: 0.0594\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933]\n",
      "Epoch [40/100], Train Loss: 0.0574, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403]\n",
      "Epoch [41/100], Train Loss: 0.0574, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345]\n",
      "Epoch [42/100], Train Loss: 0.0574, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804]\n",
      "Epoch [43/100], Train Loss: 0.0574, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896]\n",
      "Epoch [44/100], Train Loss: 0.0573, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714]\n",
      "Epoch [45/100], Train Loss: 0.0573, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931]\n",
      "Epoch [46/100], Train Loss: 0.0573, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169]\n",
      "Epoch [47/100], Train Loss: 0.0573, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435]\n",
      "Epoch [48/100], Train Loss: 0.0573, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077]\n",
      "Epoch [49/100], Train Loss: 0.0573, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236]\n",
      "Epoch [50/100], Train Loss: 0.0573, Valid Loss: 0.0593\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986]\n",
      "Epoch [51/100], Train Loss: 0.0573, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489]\n",
      "Epoch [52/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455]\n",
      "Epoch [53/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136]\n",
      "Epoch [54/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461]\n",
      "Epoch [55/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285]\n",
      "Epoch [56/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884]\n",
      "Epoch [57/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584]\n",
      "Epoch [58/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017]\n",
      "Epoch [59/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224]\n",
      "Epoch [60/100], Train Loss: 0.0572, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344]\n",
      "Epoch [61/100], Train Loss: 0.0572, Valid Loss: 0.0590\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975]\n",
      "Epoch [62/100], Train Loss: 0.0572, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348]\n",
      "Epoch [63/100], Train Loss: 0.0572, Valid Loss: 0.0592\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301, 0.057186849451208686]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348, 0.059167284375199906]\n",
      "Epoch [64/100], Train Loss: 0.0572, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301, 0.057186849451208686, 0.057172844128077285]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348, 0.059167284375199906, 0.05905854770054038]\n",
      "Epoch [65/100], Train Loss: 0.0571, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301, 0.057186849451208686, 0.057172844128077285, 0.05714872433658106]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348, 0.059167284375199906, 0.05905854770054038, 0.05913753316809352]\n",
      "Epoch [66/100], Train Loss: 0.0572, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301, 0.057186849451208686, 0.057172844128077285, 0.05714872433658106, 0.057178506686026795]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348, 0.059167284375199906, 0.05905854770054038, 0.05913753316809352, 0.05906878615944432]\n",
      "Epoch [67/100], Train Loss: 0.0572, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301, 0.057186849451208686, 0.057172844128077285, 0.05714872433658106, 0.057178506686026795, 0.05716003622994365]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348, 0.059167284375199906, 0.05905854770054038, 0.05913753316809352, 0.05906878615944432, 0.05905504155760774]\n",
      "Epoch [68/100], Train Loss: 0.0572, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301, 0.057186849451208686, 0.057172844128077285, 0.05714872433658106, 0.057178506686026795, 0.05716003622994365, 0.05715577152658658]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348, 0.059167284375199906, 0.05905854770054038, 0.05913753316809352, 0.05906878615944432, 0.05905504155760774, 0.05911521133608543]\n",
      "Epoch [69/100], Train Loss: 0.0571, Valid Loss: 0.0591\n",
      "loss_train:  [0.7753308021160493, 0.2982125556612589, 0.1211454829717257, 0.07237367698227067, 0.0634635621794017, 0.06241131266017994, 0.06225433197904782, 0.062131427264357185, 0.06199004406850022, 0.061854082283126305, 0.061716959643435765, 0.06154184707676072, 0.06136136718363647, 0.06102860784494733, 0.06041597888232714, 0.05978616156491889, 0.059389380383563325, 0.05912472509655608, 0.05893777440111321, 0.05878872179302824, 0.0586662092481751, 0.058568525942693274, 0.05848877154380442, 0.058420318338167236, 0.0583445957895503, 0.05826969684427043, 0.058188811842217504, 0.058131390109837776, 0.05803704192659941, 0.057951967211731945, 0.05784748215452734, 0.057709974804556516, 0.05763991243508925, 0.05757593988295061, 0.05754123855247555, 0.057497174696749954, 0.05746493573827916, 0.057439037708632915, 0.05743336905556989, 0.05741721122379763, 0.05739072296454246, 0.05736412172576031, 0.057363828576831935, 0.057331231460872906, 0.05729544856641666, 0.057303314754761844, 0.05729890473815332, 0.05729521661099181, 0.0572796574019524, 0.05726235135492072, 0.057259689675397185, 0.05724357889897852, 0.05724245009113507, 0.05722430189510426, 0.057210126824407695, 0.05723977816033076, 0.05720991793885288, 0.057209013267812955, 0.057219774769731314, 0.05720037068408656, 0.05718944786363338, 0.05718927696706301, 0.057186849451208686, 0.057172844128077285, 0.05714872433658106, 0.057178506686026795, 0.05716003622994365, 0.05715577152658658, 0.0571411545915776]\n",
      "vaild_train:  [0.490129167930438, 0.19161167869774196, 0.09159637142259341, 0.06775273841160995, 0.06348788179457188, 0.06275213599348298, 0.06252921623392747, 0.06239543049238049, 0.0622561711531419, 0.0620543140058334, 0.061881998768792704, 0.06169940821396617, 0.061479565723297686, 0.061271381385337845, 0.061103643562931284, 0.06104152348752205, 0.06086540806035583, 0.06075378998111074, 0.060583103269052044, 0.060421968810260296, 0.060270479844453245, 0.06021064068548954, 0.06007871440110298, 0.060113667797010675, 0.06004873946165809, 0.05998894855236778, 0.059946767341058985, 0.059748992502975926, 0.05969398307542388, 0.05971233510913757, 0.05962697051178951, 0.05954070271064456, 0.05946014499148497, 0.059470450827995174, 0.05928066480331696, 0.059406057286721006, 0.0593464495972372, 0.05933924789468829, 0.05940761212975933, 0.05929881187442403, 0.059253277436185345, 0.059262619712031804, 0.05920990699758896, 0.059264061184456714, 0.05921673301893931, 0.05917526846035169, 0.05924503680748435, 0.05920868861274077, 0.059206059345832236, 0.059304228804718986, 0.05918797728820489, 0.05916958667624455, 0.05917648376467136, 0.05916638898018461, 0.05923160151220285, 0.059204369926681884, 0.05919121875642584, 0.05918471636967017, 0.059181309591692224, 0.059108603172577344, 0.05904121324419975, 0.0591470616726348, 0.059167284375199906, 0.05905854770054038, 0.05913753316809352, 0.05906878615944432, 0.05905504155760774, 0.05911521133608543, 0.059091518776348]\n",
      "Epoch [70/100], Train Loss: 0.0572, Valid Loss: 0.0591\n",
      "Early stopped at epoch 69, train loss stop improving\n",
      "Training finished\n",
      "245.48952317237854\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "es_cnt = 0\n",
    "es_thres = 5\n",
    "prev_train_loss = float('inf')\n",
    "loss_train = []\n",
    "loss_vaild = []\n",
    "num_epochs = 100 # 总训练轮数\n",
    "#num_batch_train = 0\n",
    "for epoch in range(num_epochs):\n",
    "  #train_bar = tqdm(train_loader)\n",
    "  train_loss = 0.0\n",
    "  \n",
    "  for i , (batch) in enumerate(train_loader):\n",
    "\n",
    "    # 数据转到device\n",
    "    train_batch = batch[0].to(device)\n",
    "    \n",
    "    # 训练步骤  \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_batch)\n",
    "    loss = criterion(outputs, train_batch)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    #num_batch_train +=1\n",
    "  #train_loss除以所有bacth个数\n",
    "  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "  loss_train.append(train_loss)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  # 验证\n",
    "  valid_loss = 0.0\n",
    "  #num_batch_vaild = 0\n",
    "  with torch.no_grad():\n",
    "    for i , (batch) in enumerate(vaild_loader):\n",
    "    #for batch in vaild_loader:\n",
    "    \n",
    "      val_batch = batch[0].to(device)\n",
    "      \n",
    "      outputs = model(val_batch)\n",
    "      loss = criterion(outputs, val_batch)\n",
    "      valid_loss += loss.item()\n",
    "      #num_batch_vaild += 1\n",
    "    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "    loss_vaild.append(valid_loss)\n",
    "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "\n",
    "    \n",
    "    # Early stopping\n",
    "    if train_loss - prev_train_loss >= 0:\n",
    "        es_cnt += 1\n",
    "    else:\n",
    "        #es_cnt = 0\n",
    "        pass\n",
    "\n",
    "    if es_cnt >= es_thres:\n",
    "        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "        break  \n",
    "\n",
    "    prev_train_loss = train_loss\n",
    "  print('loss_train: ', loss_train)\n",
    "  print('vaild_train: ',loss_vaild)          \n",
    "print(\"Training finished\")\n",
    "current_time = time.time()\n",
    "time_sum = current_time-start_time\n",
    "print(time_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = pd.DataFrame(loss_train)\n",
    "loss_vaild = pd.DataFrame(loss_vaild)\n",
    "\n",
    "loss = pd.concat([loss_train,loss_vaild],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.columns = ['train_loss','vaild_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r'.\\model_2dsyn1patch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33142, 2304])\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(w1*w2,w1*w2).to(device)\n",
    "data = data.to(device)\n",
    "model.load_state_dict(torch.load(r'.\\model_2dsyn1patch.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "    #loss = criterion(output, data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.cpu()\n",
    "output = output.numpy()\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to_csv(r'loss_2dsyn1patch.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r'./output_2dsyn1patch.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_0 = []\n",
    "#start_time = time.time()\n",
    "#es_cnt = 0\n",
    "#es_thres = 5\n",
    "#prev_train_loss = float('inf')\n",
    "#loss_train = []\n",
    "#loss_vaild = []\n",
    "#num_epochs = 100 # 总训练轮数\n",
    "##num_batch_train = 0\n",
    "#for epoch in range(num_epochs):\n",
    "#  #train_bar = tqdm(train_loader)\n",
    "#  train_loss = 0.0\n",
    "#  \n",
    "#  for i , (batch) in enumerate(train_loader):\n",
    "#\n",
    "#    # 数据转到device\n",
    "#    train_batch = batch[0].to(device)\n",
    "#    \n",
    "#    # 训练步骤  \n",
    "#    optimizer.zero_grad()\n",
    "#    outputs = model(train_batch)\n",
    "#    loss = criterion(outputs, train_batch)\n",
    "#    loss.backward() \n",
    "#    optimizer.step()\n",
    "#\n",
    "#    loss_0.append(loss.item())\n",
    "#\n",
    "#    train_loss += loss.item()\n",
    "#    #num_batch_train +=1\n",
    "#  #train_loss除以所有bacth个数\n",
    "#  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "#  loss_train.append(train_loss)\n",
    "#    \n",
    "#\n",
    "#\n",
    "#\n",
    "#  # 验证\n",
    "#  valid_loss = 0.0\n",
    "#  #num_batch_vaild = 0\n",
    "#  with torch.no_grad():\n",
    "#    for i , (batch) in enumerate(vaild_loader):\n",
    "#    #for batch in vaild_loader:\n",
    "#    \n",
    "#      val_batch = batch[0].to(device)\n",
    "#      \n",
    "#      outputs = model(val_batch)\n",
    "#      loss = criterion(outputs, val_batch)\n",
    "#      valid_loss += loss.item()\n",
    "#      #num_batch_vaild += 1\n",
    "#    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "#    loss_vaild.append(valid_loss)\n",
    "#    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "#\n",
    "#    \n",
    "#    # Early stopping\n",
    "#    if train_loss - prev_train_loss >= 0:\n",
    "#        es_cnt += 1\n",
    "#    else:\n",
    "#        #es_cnt = 0\n",
    "#        pass\n",
    "#\n",
    "#    if es_cnt >= es_thres:\n",
    "#        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "#        break  \n",
    "#    \n",
    "#\n",
    "#\n",
    "##   if epoch == 10:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs10.pth')\n",
    "##   elif epoch == 20:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs20.pth')\n",
    "##   elif epoch == 30:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs30.pth')\n",
    "##   elif epoch == 40:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs40.pth')\n",
    "##   elif epoch == 50:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs50.pth')\n",
    "##   elif epoch == 60:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs60.pth')\n",
    "##   elif epoch == 70:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs70.pth')\n",
    "##   elif epoch == 80:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs80.pth')\n",
    "##   elif epoch == 90:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs90.pth')\n",
    "##   elif epoch == 100:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs100.pth')\n",
    "##   else:\n",
    "##       pass\n",
    "#\n",
    "#    prev_train_loss = train_loss\n",
    "#  print('loss_train: ', loss_train)\n",
    "#  print('vaild_train: ',loss_vaild)          \n",
    "#print(\"Training finished\")\n",
    "#current_time = time.time()\n",
    "#time_sum = current_time-start_time\n",
    "#print(time_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
