{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import tushare as ts\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_noisy = r'Input_Patches_2Dreal1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_noisy, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)\n",
    "data= torch.from_numpy(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22364, 1024])\n",
      "torch.Size([5592, 1024])\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "vaild = data[train_size:]\n",
    "print(train.shape)\n",
    "print(vaild.shape)\n",
    "batch_size1 = 64\n",
    "w1 = 32\n",
    "w2 = 32\n",
    "\n",
    "train_data= TensorDataset(train)\n",
    "vaild_data= TensorDataset(vaild)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size = 64,\n",
    "                                           shuffle = True)\n",
    "\n",
    "vaild_loader = torch.utils.data.DataLoader(vaild_data,\n",
    "                                          batch_size = 64,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Fully connected (FC) block\n",
    "class FCB(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.bn = nn.BatchNorm1d(output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAB(nn.Module):  ##position attention block\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fcb1 = FCB(input_size, output_size, dropout)\n",
    "        self.fcb2 = FCB(input_size, output_size, dropout)\n",
    "        self.fcb3 = FCB(input_size, output_size, dropout)\n",
    "        self.fcb4 = FCB(input_size, output_size, dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.fcb1(x)\n",
    "        x2 = self.fcb2(x)\n",
    "        x3 = self.fcb3(x)\n",
    "        x4 = self.fcb4(x)\n",
    "        \n",
    "\n",
    "        x = x1*x2\n",
    "        x = self.softmax(x)\n",
    "        x = x*x3\n",
    "        x = x+x4\n",
    "        \n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cov1d = nn.Conv1d(in_channels=1, out_channels= 64 ,kernel_size = 6, padding=0, stride=1)\n",
    "\n",
    "        self.pab1 = PAB(int(input_size-6+1), 128, dropout)\n",
    "        self.fcb1 = FCB(128, 128, dropout)\n",
    "\n",
    "        self.pab2 = PAB(128, 64, dropout)\n",
    "        self.fcb2 = FCB(64, 64, dropout)\n",
    "\n",
    "        self.pab3 = PAB(64, 32, dropout)\n",
    "        self.fcb3 = FCB(32, 32, dropout)\n",
    "\n",
    "        self.pab4 = PAB(32, 16, dropout)\n",
    "        self.fcb4 = FCB(16, 16, dropout)\n",
    "\n",
    "        self.pab5 = PAB(16, 8, dropout)\n",
    "        self.fcb5 = FCB(8, 8, dropout)\n",
    "\n",
    "        self.pab6 = PAB(8, 4, dropout)\n",
    "        self.fcb6 = FCB(4, 4, dropout)\n",
    "        \n",
    "        self.fcb7 = FCB(4, 4, dropout)\n",
    "        self.pab7 = PAB(4, 4, dropout)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1])\n",
    "        x = self.cov1d(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = nn.AdaptiveAvgPool1d(1)(x)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x1 = self.pab1(x)\n",
    "        x13 = self.fcb1(x1)\n",
    "\n",
    "        x2 = self.pab2(x1)\n",
    "        x12 = self.fcb2(x2)\n",
    "\n",
    "        x3 = self.pab3(x2)\n",
    "        x11 = self.fcb3(x3)\n",
    "\n",
    "        x4 = self.pab4(x3)\n",
    "        x10 = self.fcb4(x4)\n",
    "\n",
    "        x5 = self.pab5(x4)\n",
    "        x9 = self.fcb5(x5)\n",
    "\n",
    "        x6 = self.pab6(x5)\n",
    "        x8 = self.fcb6(x6)\n",
    "\n",
    "        x7 = self.fcb7(x6)\n",
    "        x7 = self.pab7(x7)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        return x7,x8,x9,x10,x11,x12,x13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomActivation(torch.autograd.Function):    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "\n",
    "        ctx.save_for_backward(x)\n",
    "        y =7/3 * (x - torch.tanh(x)) * torch.cos(x/2)\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "\n",
    "        x, = ctx.saved_tensors\n",
    "        grad_x = grad_output * (7/3 * ((torch.cos(x/2)*(1 - torch.pow(torch.cosh(x), -2)))+ (x - torch.tanh(x))*(-0.5*torch.sin(x/2))))\n",
    "                                       \n",
    "        return grad_x\n",
    "    \n",
    "class CustomActivationModule(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return CustomActivation.apply(x)  \n",
    "    \n",
    "\n",
    "activation = CustomActivationModule()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pab1 = PAB(8, 8, dropout)\n",
    "        self.pab2 = PAB(16, 16, dropout)\n",
    "        self.pab3 = PAB(32, 32, dropout)\n",
    "        self.pab4 = PAB(64, 64, dropout)\n",
    "        self.pab5 = PAB(128, 128, dropout)\n",
    "  \n",
    "\n",
    "        self.fc = nn.Linear(256,output_size)\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "    def forward(self, x7,x8,x9,x10,x11,x12,x13):\n",
    "        \n",
    "        x = torch.cat((x7,x8),dim=1)\n",
    "        x = self.pab1(x)\n",
    "        x = torch.cat((x,x9),dim=1)\n",
    "        x = self.pab2(x)\n",
    "        x = torch.cat((x,x10),dim=1)\n",
    "        x = self.pab3(x)\n",
    "        x = torch.cat((x,x11),dim=1)\n",
    "        x = self.pab4(x)\n",
    "        x = torch.cat((x,x12),dim=1)\n",
    "        x = self.pab5(x)\n",
    "        x = torch.cat((x,x13),dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size)\n",
    "        self.decoder = Decoder(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x7,x8,x9,x10,x11,x12,x13= self.encoder(x)\n",
    "        x = self.decoder(x7,x8,x9,x10,x11,x12,x13)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WelschLoss(nn.Module):\n",
    "    def __init__(self, delta):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        x = y_true - y_pred\n",
    "        loss = 1 - torch.exp(-0.5 * torch.pow((x / self.delta),2))\n",
    "        return torch.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanHuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.3):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        error = y_true - y_pred\n",
    "        cond = torch.abs(error) < self.delta\n",
    "\n",
    "        squared_loss = 0.5 * torch.pow(error, 2)\n",
    "        linear_loss = self.delta * (torch.abs(error) - 0.5 * self.delta)\n",
    "        loss = torch.where(cond, squared_loss, linear_loss)\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self,delta,r):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.r = r\n",
    "    def forward(self,input,output):\n",
    "        N = input-output\n",
    "        temp = output*N\n",
    "        temp1 = data.shape[1]*(temp.sum(1))\n",
    "        temp2 = (output.sum(1))*(N.sum(1))\n",
    "        temp3 = torch.pow(data.shape[1]*((output**2).sum(1)) - ((output.sum(1))**2),1/2)\n",
    "        temp4 = torch.pow(data.shape[1]*((N**2).sum(1))-((N.sum(1))**2),1/2) \n",
    "        loss = torch.pow((temp1-temp2)/(temp3*temp4),2)\n",
    "\n",
    "        a = torch.min(loss)\n",
    "        b = torch.mean(1 - torch.exp(-0.5 * torch.pow((N / self.delta),2)))\n",
    "        return self.r*a+(1-self.r)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss0(nn.Module):\n",
    "    def __init__(self,delta,r):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.r = r\n",
    "    def forward(self,input,output):\n",
    "        N = input-output\n",
    "        b = torch.mean(1 - torch.exp(-0.5 * torch.pow((N / self.delta),2)))\n",
    "        K = output.shape[0]\n",
    "        y2_mean = torch.mean(output)\n",
    "        n2_mean = torch.mean(N)\n",
    "        covariance = 0.0\n",
    "        variance_y2 = 0.0\n",
    "        variance_n2 = 0.0\n",
    "        for j in range(K):\n",
    "            y2_sample = output[j, :]\n",
    "            n2_sample = N[j, :]\n",
    "            covariance += ((y2_sample - y2_mean) * (n2_sample - n2_mean))\n",
    "            variance_y2 += ((y2_sample - y2_mean) ** 2)\n",
    "            variance_n2 += ((n2_sample - n2_mean) ** 2)\n",
    "            lcc_value = (covariance / torch.sqrt(variance_y2 * variance_n2)) ** 2\n",
    "            lcc_value = torch.mean(lcc_value)\n",
    "        return self.r*lcc_value+(1-self.r)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "model = AutoEncoder(w1*w2,w1*w2).to(device)\n",
    "\n",
    "criterion = Loss0(delta=0.42,r=0.01) \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Train Loss: 0.2175, Valid Loss: 0.1704\n",
      "loss_train:  [0.21750491048608508]\n",
      "vaild_train:  [0.1704373127696189]\n",
      "Epoch [2/80], Train Loss: 0.1863, Valid Loss: 0.1656\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005]\n",
      "Epoch [3/80], Train Loss: 0.1797, Valid Loss: 0.1634\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865]\n",
      "Epoch [4/80], Train Loss: 0.1768, Valid Loss: 0.1622\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111]\n",
      "Epoch [5/80], Train Loss: 0.1751, Valid Loss: 0.1616\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864]\n",
      "Epoch [6/80], Train Loss: 0.1738, Valid Loss: 0.1603\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526]\n",
      "Epoch [7/80], Train Loss: 0.1728, Valid Loss: 0.1595\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502]\n",
      "Epoch [8/80], Train Loss: 0.1721, Valid Loss: 0.1593\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948]\n",
      "Epoch [9/80], Train Loss: 0.1714, Valid Loss: 0.1585\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487]\n",
      "Epoch [10/80], Train Loss: 0.1710, Valid Loss: 0.1592\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235]\n",
      "Epoch [11/80], Train Loss: 0.1704, Valid Loss: 0.1585\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094]\n",
      "Epoch [12/80], Train Loss: 0.1700, Valid Loss: 0.1590\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635]\n",
      "Epoch [13/80], Train Loss: 0.1696, Valid Loss: 0.1574\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317]\n",
      "Epoch [14/80], Train Loss: 0.1692, Valid Loss: 0.1579\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831]\n",
      "Epoch [15/80], Train Loss: 0.1689, Valid Loss: 0.1577\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273]\n",
      "Epoch [16/80], Train Loss: 0.1685, Valid Loss: 0.1580\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065]\n",
      "Epoch [17/80], Train Loss: 0.1682, Valid Loss: 0.1570\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427]\n",
      "Epoch [18/80], Train Loss: 0.1679, Valid Loss: 0.1573\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303]\n",
      "Epoch [19/80], Train Loss: 0.1677, Valid Loss: 0.1583\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062]\n",
      "Epoch [20/80], Train Loss: 0.1675, Valid Loss: 0.1572\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312]\n",
      "Epoch [21/80], Train Loss: 0.1672, Valid Loss: 0.1566\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772]\n",
      "Epoch [22/80], Train Loss: 0.1670, Valid Loss: 0.1567\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243]\n",
      "Epoch [23/80], Train Loss: 0.1668, Valid Loss: 0.1575\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653]\n",
      "Epoch [24/80], Train Loss: 0.1665, Valid Loss: 0.1566\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923]\n",
      "Epoch [25/80], Train Loss: 0.1664, Valid Loss: 0.1573\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708]\n",
      "Epoch [26/80], Train Loss: 0.1662, Valid Loss: 0.1558\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129]\n",
      "Epoch [27/80], Train Loss: 0.1661, Valid Loss: 0.1561\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703]\n",
      "Epoch [28/80], Train Loss: 0.1659, Valid Loss: 0.1569\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878]\n",
      "Epoch [29/80], Train Loss: 0.1657, Valid Loss: 0.1562\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704]\n",
      "Epoch [30/80], Train Loss: 0.1657, Valid Loss: 0.1576\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923]\n",
      "Epoch [31/80], Train Loss: 0.1655, Valid Loss: 0.1563\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894]\n",
      "Epoch [32/80], Train Loss: 0.1653, Valid Loss: 0.1562\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135]\n",
      "Epoch [33/80], Train Loss: 0.1652, Valid Loss: 0.1564\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054]\n",
      "Epoch [34/80], Train Loss: 0.1651, Valid Loss: 0.1553\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038]\n",
      "Epoch [35/80], Train Loss: 0.1650, Valid Loss: 0.1565\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936]\n",
      "Epoch [36/80], Train Loss: 0.1648, Valid Loss: 0.1549\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256]\n",
      "Epoch [37/80], Train Loss: 0.1647, Valid Loss: 0.1556\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456]\n",
      "Epoch [38/80], Train Loss: 0.1646, Valid Loss: 0.1549\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992]\n",
      "Epoch [39/80], Train Loss: 0.1644, Valid Loss: 0.1555\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156]\n",
      "Epoch [40/80], Train Loss: 0.1643, Valid Loss: 0.1561\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288]\n",
      "Epoch [41/80], Train Loss: 0.1643, Valid Loss: 0.1552\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676]\n",
      "Epoch [42/80], Train Loss: 0.1641, Valid Loss: 0.1558\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935]\n",
      "Epoch [43/80], Train Loss: 0.1641, Valid Loss: 0.1542\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056]\n",
      "Epoch [44/80], Train Loss: 0.1639, Valid Loss: 0.1547\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192]\n",
      "Epoch [45/80], Train Loss: 0.1638, Valid Loss: 0.1554\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808]\n",
      "Epoch [46/80], Train Loss: 0.1637, Valid Loss: 0.1538\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815]\n",
      "Epoch [47/80], Train Loss: 0.1636, Valid Loss: 0.1544\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052]\n",
      "Epoch [48/80], Train Loss: 0.1635, Valid Loss: 0.1544\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765]\n",
      "Epoch [49/80], Train Loss: 0.1633, Valid Loss: 0.1545\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272]\n",
      "Epoch [50/80], Train Loss: 0.1633, Valid Loss: 0.1543\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496]\n",
      "Epoch [51/80], Train Loss: 0.1631, Valid Loss: 0.1551\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314]\n",
      "Epoch [52/80], Train Loss: 0.1631, Valid Loss: 0.1543\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754]\n",
      "Epoch [53/80], Train Loss: 0.1629, Valid Loss: 0.1554\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045]\n",
      "Epoch [54/80], Train Loss: 0.1628, Valid Loss: 0.1539\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629]\n",
      "Epoch [55/80], Train Loss: 0.1628, Valid Loss: 0.1545\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306]\n",
      "Epoch [56/80], Train Loss: 0.1628, Valid Loss: 0.1546\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306]\n",
      "Epoch [57/80], Train Loss: 0.1627, Valid Loss: 0.1546\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606]\n",
      "Epoch [58/80], Train Loss: 0.1626, Valid Loss: 0.1546\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828]\n",
      "Epoch [59/80], Train Loss: 0.1626, Valid Loss: 0.1549\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876]\n",
      "Epoch [60/80], Train Loss: 0.1625, Valid Loss: 0.1545\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387]\n",
      "Epoch [61/80], Train Loss: 0.1623, Valid Loss: 0.1551\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272]\n",
      "Epoch [62/80], Train Loss: 0.1622, Valid Loss: 0.1546\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308]\n",
      "Epoch [63/80], Train Loss: 0.1622, Valid Loss: 0.1545\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529]\n",
      "Epoch [64/80], Train Loss: 0.1621, Valid Loss: 0.1541\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219]\n",
      "Epoch [65/80], Train Loss: 0.1620, Valid Loss: 0.1561\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914]\n",
      "Epoch [66/80], Train Loss: 0.1619, Valid Loss: 0.1550\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357]\n",
      "Epoch [67/80], Train Loss: 0.1618, Valid Loss: 0.1541\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804]\n",
      "Epoch [68/80], Train Loss: 0.1616, Valid Loss: 0.1549\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674]\n",
      "Epoch [69/80], Train Loss: 0.1616, Valid Loss: 0.1546\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774]\n",
      "Epoch [70/80], Train Loss: 0.1615, Valid Loss: 0.1541\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866]\n",
      "Epoch [71/80], Train Loss: 0.1614, Valid Loss: 0.1542\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364]\n",
      "Epoch [72/80], Train Loss: 0.1613, Valid Loss: 0.1536\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991]\n",
      "Epoch [73/80], Train Loss: 0.1612, Valid Loss: 0.1543\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766]\n",
      "Epoch [74/80], Train Loss: 0.1610, Valid Loss: 0.1542\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791, 0.16102777187313352]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766, 0.15418364869599993]\n",
      "Epoch [75/80], Train Loss: 0.1609, Valid Loss: 0.1537\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791, 0.16102777187313352, 0.16088131070137024]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766, 0.15418364869599993, 0.15373911149799824]\n",
      "Epoch [76/80], Train Loss: 0.1608, Valid Loss: 0.1543\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791, 0.16102777187313352, 0.16088131070137024, 0.16075537200484957]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766, 0.15418364869599993, 0.15373911149799824, 0.1543152757327665]\n",
      "Epoch [77/80], Train Loss: 0.1607, Valid Loss: 0.1541\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791, 0.16102777187313352, 0.16088131070137024, 0.16075537200484957, 0.16065503925085067]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766, 0.15418364869599993, 0.15373911149799824, 0.1543152757327665, 0.15408294106071646]\n",
      "Epoch [78/80], Train Loss: 0.1606, Valid Loss: 0.1543\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791, 0.16102777187313352, 0.16088131070137024, 0.16075537200484957, 0.16065503925085067, 0.1605746425475393]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766, 0.15418364869599993, 0.15373911149799824, 0.1543152757327665, 0.15408294106071646, 0.1542989110404795]\n",
      "Epoch [79/80], Train Loss: 0.1604, Valid Loss: 0.1533\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791, 0.16102777187313352, 0.16088131070137024, 0.16075537200484957, 0.16065503925085067, 0.1605746425475393, 0.16042049327066968]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766, 0.15418364869599993, 0.15373911149799824, 0.1543152757327665, 0.15408294106071646, 0.1542989110404795, 0.1533156858587807]\n",
      "Epoch [80/80], Train Loss: 0.1603, Valid Loss: 0.1546\n",
      "loss_train:  [0.21750491048608508, 0.18625682336943492, 0.17974657761199134, 0.17682096234389713, 0.17507226880107607, 0.1737577350650515, 0.1727953639626503, 0.17211508188928876, 0.1714327924166407, 0.17095460538353238, 0.17039290572915758, 0.1699834054708481, 0.16961492257458824, 0.16918567261525563, 0.16888491183519364, 0.1684964480996132, 0.16818225984062468, 0.16791917532682418, 0.16770211381571634, 0.1675070384996278, 0.1672160057936396, 0.16696316919156484, 0.16682544146265302, 0.166535935487066, 0.1663713182721819, 0.1662256483095033, 0.16606854042836597, 0.16589351321969714, 0.16572300732135772, 0.16565817756312234, 0.1655319435255868, 0.16530800644840513, 0.16518100649118422, 0.16506891804082052, 0.16495497103248324, 0.16478456829275404, 0.16469320246151514, 0.16461878022977283, 0.16443558663129806, 0.16434867471456527, 0.16427611082792282, 0.16407125328268324, 0.16405428779976708, 0.16390199367489133, 0.16379661147083555, 0.1636950296163559, 0.16355992806809289, 0.1634894222872598, 0.16334791434662682, 0.16329894491604396, 0.16314622772591456, 0.1630620961529868, 0.16292387008666992, 0.16281049174921852, 0.16282437396900995, 0.16278733870812825, 0.16267118211303438, 0.16255782123122897, 0.16259847096034458, 0.16245124472039085, 0.162321902854102, 0.16217260990824017, 0.1622076409629413, 0.16206402791397911, 0.16202538916042872, 0.16185481556824274, 0.16176993012428284, 0.16164511442184448, 0.16158483637230736, 0.16150456326348442, 0.16138080124344145, 0.16126096606254578, 0.16117796795708791, 0.16102777187313352, 0.16088131070137024, 0.16075537200484957, 0.16065503925085067, 0.1605746425475393, 0.16042049327066968, 0.1603351412500654]\n",
      "vaild_train:  [0.1704373127696189, 0.16564181802625005, 0.16341615620661865, 0.1622324917804111, 0.1616375075483864, 0.16030111400918526, 0.15952601876448502, 0.15930623324079948, 0.1584583128040487, 0.15918490222909235, 0.1584954090755094, 0.15895310044288635, 0.15744343620132317, 0.1579277620396831, 0.15770523283969273, 0.15804501351985065, 0.15699969977140427, 0.15732833116569303, 0.15826164338399062, 0.15724767270413312, 0.15660320713438772, 0.15669965828684243, 0.15750134753232653, 0.15658316473391923, 0.15725502947514708, 0.1557975033806129, 0.15609458935531703, 0.15692503089931878, 0.15618539059704, 0.15758588181977923, 0.15626011399382894, 0.156233223663135, 0.1564071544192054, 0.15527764623138038, 0.15654627758670936, 0.15491890619424256, 0.15559135055677456, 0.15486902625045992, 0.15550731173293156, 0.15614174628122288, 0.15522429888898676, 0.15582103248346935, 0.15418257293376056, 0.1547023816542192, 0.15541383742608808, 0.15379555557261815, 0.15437488020821052, 0.1544246548278765, 0.15445280447602272, 0.15427384034476496, 0.1550833767449314, 0.15430707365951754, 0.15539652346210045, 0.1539173276925629, 0.1544737812470306, 0.15458063764328306, 0.15456166880374606, 0.15459124422208828, 0.15490696697749876, 0.15445492924614387, 0.15514275465499272, 0.15460479547354308, 0.1545150445943529, 0.1541482765566219, 0.15608976493504914, 0.15500163777985357, 0.1540786332704804, 0.15491161681711674, 0.15463622777976774, 0.15407115627418866, 0.15424211458726364, 0.153631974180991, 0.15430376746437766, 0.15418364869599993, 0.15373911149799824, 0.1543152757327665, 0.15408294106071646, 0.1542989110404795, 0.1533156858587807, 0.15458729304373264]\n",
      "Training finished\n",
      "2411.515655040741\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "es_cnt = 0\n",
    "es_thres = 10\n",
    "prev_train_loss = float('inf')\n",
    "loss_train = []\n",
    "loss_vaild = []\n",
    "num_epochs = 80 #\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss = 0.0\n",
    "  \n",
    "  for i , (batch) in enumerate(train_loader):\n",
    "\n",
    "    train_batch = batch[0].to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_batch)\n",
    "    loss = criterion(outputs, train_batch)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "  loss_train.append(train_loss)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  valid_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for i , (batch) in enumerate(vaild_loader):\n",
    "    \n",
    "      val_batch = batch[0].to(device)\n",
    "      \n",
    "      outputs = model(val_batch)\n",
    "      loss = criterion(outputs, val_batch)\n",
    "      valid_loss += loss.item()\n",
    "    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "    loss_vaild.append(valid_loss)\n",
    "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "\n",
    "    \n",
    "    # Early stopping\n",
    "    if train_loss - prev_train_loss >= 0:\n",
    "        es_cnt += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if es_cnt >= es_thres:\n",
    "        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "        break  \n",
    "\n",
    "    prev_train_loss = train_loss\n",
    "  print('loss_train: ', loss_train)\n",
    "  print('vaild_train: ',loss_vaild)          \n",
    "print(\"Training finished\")\n",
    "current_time = time.time()\n",
    "time_sum = current_time-start_time\n",
    "print(time_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = pd.DataFrame(loss_train)\n",
    "loss_vaild = pd.DataFrame(loss_vaild)\n",
    "\n",
    "loss = pd.concat([loss_train,loss_vaild],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.columns = ['train_loss','vaild_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to_csv(r'loss_2dreal1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r'.\\model_2dreal1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27956, 1024])\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(w1*w2,w1*w2).to(device)\n",
    "data = data.to(device)\n",
    "model.load_state_dict(torch.load(r'.\\model_2dreal1.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.cpu()\n",
    "output = output.numpy()\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r'./output_2dreal1.csv',index=None,header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
