{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import tushare as ts\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_noisy = r'Input_Patches_3Dreal2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_noisy, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1718</th>\n",
       "      <th>1719</th>\n",
       "      <th>1720</th>\n",
       "      <th>1721</th>\n",
       "      <th>1722</th>\n",
       "      <th>1723</th>\n",
       "      <th>1724</th>\n",
       "      <th>1725</th>\n",
       "      <th>1726</th>\n",
       "      <th>1727</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.815578</td>\n",
       "      <td>0.763338</td>\n",
       "      <td>0.754059</td>\n",
       "      <td>-1.111491</td>\n",
       "      <td>1.265898</td>\n",
       "      <td>2.840581</td>\n",
       "      <td>-0.011243</td>\n",
       "      <td>-1.028299</td>\n",
       "      <td>-0.803838</td>\n",
       "      <td>1.447028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633431</td>\n",
       "      <td>-0.186204</td>\n",
       "      <td>-0.370927</td>\n",
       "      <td>0.299487</td>\n",
       "      <td>0.144882</td>\n",
       "      <td>0.070218</td>\n",
       "      <td>0.506113</td>\n",
       "      <td>0.159219</td>\n",
       "      <td>0.114936</td>\n",
       "      <td>0.496620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.563465</td>\n",
       "      <td>0.617968</td>\n",
       "      <td>0.211230</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.504243</td>\n",
       "      <td>0.208796</td>\n",
       "      <td>-0.138585</td>\n",
       "      <td>-0.537625</td>\n",
       "      <td>-0.622966</td>\n",
       "      <td>-0.595773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337196</td>\n",
       "      <td>0.079985</td>\n",
       "      <td>-0.198906</td>\n",
       "      <td>-0.382787</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>-0.488307</td>\n",
       "      <td>-0.297148</td>\n",
       "      <td>-0.237758</td>\n",
       "      <td>-0.083351</td>\n",
       "      <td>0.332818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000380</td>\n",
       "      <td>-0.282182</td>\n",
       "      <td>-0.685111</td>\n",
       "      <td>-0.913809</td>\n",
       "      <td>-0.829509</td>\n",
       "      <td>-0.605626</td>\n",
       "      <td>-0.486916</td>\n",
       "      <td>-0.001499</td>\n",
       "      <td>0.206933</td>\n",
       "      <td>0.446442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299653</td>\n",
       "      <td>-0.937786</td>\n",
       "      <td>-0.769336</td>\n",
       "      <td>-0.705439</td>\n",
       "      <td>-0.713293</td>\n",
       "      <td>-0.668061</td>\n",
       "      <td>-1.134946</td>\n",
       "      <td>-0.967494</td>\n",
       "      <td>-0.506291</td>\n",
       "      <td>-0.188805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.320812</td>\n",
       "      <td>0.440913</td>\n",
       "      <td>-0.291419</td>\n",
       "      <td>-1.192542</td>\n",
       "      <td>-0.550346</td>\n",
       "      <td>-0.944047</td>\n",
       "      <td>-0.571363</td>\n",
       "      <td>0.524471</td>\n",
       "      <td>0.946202</td>\n",
       "      <td>0.685451</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.379518</td>\n",
       "      <td>-0.845387</td>\n",
       "      <td>-2.753046</td>\n",
       "      <td>-3.564230</td>\n",
       "      <td>0.005390</td>\n",
       "      <td>-1.268847</td>\n",
       "      <td>-1.281567</td>\n",
       "      <td>-1.255031</td>\n",
       "      <td>-0.646878</td>\n",
       "      <td>3.104398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.934025</td>\n",
       "      <td>0.380661</td>\n",
       "      <td>0.482202</td>\n",
       "      <td>0.363099</td>\n",
       "      <td>0.522866</td>\n",
       "      <td>0.348136</td>\n",
       "      <td>0.118047</td>\n",
       "      <td>0.602362</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206029</td>\n",
       "      <td>-0.272214</td>\n",
       "      <td>-0.910142</td>\n",
       "      <td>-0.683648</td>\n",
       "      <td>-0.899608</td>\n",
       "      <td>-0.422113</td>\n",
       "      <td>-0.247000</td>\n",
       "      <td>0.337039</td>\n",
       "      <td>0.876563</td>\n",
       "      <td>0.462564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12579</th>\n",
       "      <td>-0.271112</td>\n",
       "      <td>0.465888</td>\n",
       "      <td>0.529884</td>\n",
       "      <td>0.787988</td>\n",
       "      <td>0.880660</td>\n",
       "      <td>0.726869</td>\n",
       "      <td>0.886427</td>\n",
       "      <td>0.810713</td>\n",
       "      <td>0.832469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12580</th>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.578822</td>\n",
       "      <td>0.341261</td>\n",
       "      <td>0.726888</td>\n",
       "      <td>1.082105</td>\n",
       "      <td>0.865496</td>\n",
       "      <td>0.875879</td>\n",
       "      <td>0.631425</td>\n",
       "      <td>0.361306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12581</th>\n",
       "      <td>0.176536</td>\n",
       "      <td>-0.336254</td>\n",
       "      <td>-0.029643</td>\n",
       "      <td>0.222905</td>\n",
       "      <td>0.506781</td>\n",
       "      <td>0.452772</td>\n",
       "      <td>1.197900</td>\n",
       "      <td>1.282751</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12582</th>\n",
       "      <td>0.588327</td>\n",
       "      <td>1.053636</td>\n",
       "      <td>1.304401</td>\n",
       "      <td>1.647281</td>\n",
       "      <td>-0.391069</td>\n",
       "      <td>-0.183096</td>\n",
       "      <td>-1.315025</td>\n",
       "      <td>1.326614</td>\n",
       "      <td>1.962560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12583</th>\n",
       "      <td>0.404455</td>\n",
       "      <td>1.446354</td>\n",
       "      <td>-0.163088</td>\n",
       "      <td>-1.347798</td>\n",
       "      <td>-2.204478</td>\n",
       "      <td>4.509949</td>\n",
       "      <td>-1.192694</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.303194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12584 rows × 1728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0     -1.815578  0.763338  0.754059 -1.111491  1.265898  2.840581 -0.011243   \n",
       "1      0.563465  0.617968  0.211230  0.996051  0.504243  0.208796 -0.138585   \n",
       "2      0.000380 -0.282182 -0.685111 -0.913809 -0.829509 -0.605626 -0.486916   \n",
       "3      0.320812  0.440913 -0.291419 -1.192542 -0.550346 -0.944047 -0.571363   \n",
       "4      0.964060  0.934025  0.380661  0.482202  0.363099  0.522866  0.348136   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12579 -0.271112  0.465888  0.529884  0.787988  0.880660  0.726869  0.886427   \n",
       "12580  0.013781  0.578822  0.341261  0.726888  1.082105  0.865496  0.875879   \n",
       "12581  0.176536 -0.336254 -0.029643  0.222905  0.506781  0.452772  1.197900   \n",
       "12582  0.588327  1.053636  1.304401  1.647281 -0.391069 -0.183096 -1.315025   \n",
       "12583  0.404455  1.446354 -0.163088 -1.347798 -2.204478  4.509949 -1.192694   \n",
       "\n",
       "           7         8         9     ...      1718      1719      1720  \\\n",
       "0     -1.028299 -0.803838  1.447028  ... -0.633431 -0.186204 -0.370927   \n",
       "1     -0.537625 -0.622966 -0.595773  ...  0.337196  0.079985 -0.198906   \n",
       "2     -0.001499  0.206933  0.446442  ... -0.299653 -0.937786 -0.769336   \n",
       "3      0.524471  0.946202  0.685451  ... -1.379518 -0.845387 -2.753046   \n",
       "4      0.118047  0.602362  0.407447  ... -0.206029 -0.272214 -0.910142   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "12579  0.810713  0.832469  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "12580  0.631425  0.361306  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "12581  1.282751  0.930060  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "12582  1.326614  1.962560  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "12583  0.766667  1.303194  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "           1721      1722      1723      1724      1725      1726      1727  \n",
       "0      0.299487  0.144882  0.070218  0.506113  0.159219  0.114936  0.496620  \n",
       "1     -0.382787  0.023340 -0.488307 -0.297148 -0.237758 -0.083351  0.332818  \n",
       "2     -0.705439 -0.713293 -0.668061 -1.134946 -0.967494 -0.506291 -0.188805  \n",
       "3     -3.564230  0.005390 -1.268847 -1.281567 -1.255031 -0.646878  3.104398  \n",
       "4     -0.683648 -0.899608 -0.422113 -0.247000  0.337039  0.876563  0.462564  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "12579  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12580  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12581  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12582  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12583  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[12584 rows x 1728 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)\n",
    "data= torch.from_numpy(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12584, 1728])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10067, 1728])\n",
      "torch.Size([2517, 1728])\n"
     ]
    }
   ],
   "source": [
    "#将前80%作为训练集，后20%作为测试集\n",
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "vaild = data[train_size:]\n",
    "print(train.shape)\n",
    "print(vaild.shape)\n",
    "batch_size1 = 64\n",
    "w1 = 12\n",
    "w2 = 12\n",
    "w3 = 12\n",
    "\n",
    "train_data= TensorDataset(train)\n",
    "vaild_data= TensorDataset(vaild)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size = 64,\n",
    "                                           shuffle = True)\n",
    "\n",
    "vaild_loader = torch.utils.data.DataLoader(vaild_data,\n",
    "                                          batch_size = 64,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Fully connected (FC) block\n",
    "class FCB(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.bn = nn.BatchNorm1d(output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.fcb0 = FCB(input_size, 128, dropout)\n",
    "        self.fcb1 = FCB(128, 64, dropout)\n",
    "\n",
    "        self.fcb2 = FCB(64, 32, dropout)\n",
    "\n",
    "        self.fcb3 = FCB(32, 16, dropout)\n",
    "\n",
    "        self.fcb4 = FCB(16, 8, dropout)\n",
    "\n",
    "        self.fcb5 = FCB(8, 4, dropout)\n",
    "\n",
    "        self.fcb6 = FCB(4, 4, dropout)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = x.reshape(x.shape[0],1,x.shape[1])\n",
    "\n",
    "        x1 = self.fcb0(x)#x->128\n",
    "        x2 = self.fcb1(x1)\n",
    "\n",
    "        x3 = self.fcb2(x2)\n",
    "\n",
    "        x4 = self.fcb3(x3)\n",
    "\n",
    "        x5 = self.fcb4(x4)\n",
    "\n",
    "        x6 = self.fcb5(x5)\n",
    "\n",
    "        x7 = self.fcb6(x6)\n",
    "\n",
    "        x8 = self.fcb6(x7)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        return x2,x3,x4,x5,x6,x7,x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pab1 = FCB(8, 8, dropout)\n",
    "        self.pab2 = FCB(16, 16, dropout)\n",
    "        self.pab3 = FCB(32, 32, dropout)\n",
    "        self.pab4 = FCB(64, 64, dropout)\n",
    "        self.pab5 = FCB(128, 128, dropout)\n",
    "        self.pab6 = FCB(128, output_size, dropout)\n",
    "\n",
    "        self.activation = nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self,x2, x3,x4,x5,x6,x7,x8):\n",
    "        \n",
    "        x = torch.cat((x6,x8),dim=1)\n",
    "        x = self.pab1(x)\n",
    "        x = torch.cat((x,x5),dim=1)\n",
    "        x = self.pab2(x)\n",
    "        x = torch.cat((x,x4),dim=1)\n",
    "        x = self.pab3(x)\n",
    "        x = torch.cat((x,x3),dim=1)\n",
    "        x = self.pab4(x)\n",
    "        x = torch.cat((x,x2),dim=1)\n",
    "        x = self.pab5(x)\n",
    "        x = self.pab6(x)\n",
    "\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size)\n",
    "        self.decoder = Decoder(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2, x3,x4,x5,x6,x7,x8= self.encoder(x)\n",
    "        x = self.decoder(x2, x3,x4,x5,x6,x7,x8)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "model = AutoEncoder(w1*w2*w3,w1*w2*w3).to(device)\n",
    "#将模型转移到GPU上\n",
    "#criterion = MeanHuberLoss(delta=1.3)\n",
    "#criterion = WelschLoss(delta=0.5)\n",
    "#criterion = Loss0(delta=0.46,r=0.05)#0.5 and 0.2,SNR:-8dB ok\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.9191, Valid Loss: 0.6239\n",
      "loss_train:  [0.9191135364242747]\n",
      "vaild_train:  [0.6238858565688133]\n",
      "Epoch [2/100], Train Loss: 0.5371, Valid Loss: 0.4338\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556]\n",
      "Epoch [3/100], Train Loss: 0.4009, Valid Loss: 0.3491\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925]\n",
      "Epoch [4/100], Train Loss: 0.3376, Valid Loss: 0.3102\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379]\n",
      "Epoch [5/100], Train Loss: 0.3054, Valid Loss: 0.2911\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934]\n",
      "Epoch [6/100], Train Loss: 0.2879, Valid Loss: 0.2806\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486]\n",
      "Epoch [7/100], Train Loss: 0.2780, Valid Loss: 0.2755\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661]\n",
      "Epoch [8/100], Train Loss: 0.2714, Valid Loss: 0.2711\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569]\n",
      "Epoch [9/100], Train Loss: 0.2676, Valid Loss: 0.2676\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027]\n",
      "Epoch [10/100], Train Loss: 0.2642, Valid Loss: 0.2652\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426]\n",
      "Epoch [11/100], Train Loss: 0.2619, Valid Loss: 0.2647\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327]\n",
      "Epoch [12/100], Train Loss: 0.2605, Valid Loss: 0.2616\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763]\n",
      "Epoch [13/100], Train Loss: 0.2591, Valid Loss: 0.2601\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717]\n",
      "Epoch [14/100], Train Loss: 0.2572, Valid Loss: 0.2585\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131]\n",
      "Epoch [15/100], Train Loss: 0.2560, Valid Loss: 0.2585\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756]\n",
      "Epoch [16/100], Train Loss: 0.2549, Valid Loss: 0.2570\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972]\n",
      "Epoch [17/100], Train Loss: 0.2533, Valid Loss: 0.2557\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551]\n",
      "Epoch [18/100], Train Loss: 0.2522, Valid Loss: 0.2541\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484]\n",
      "Epoch [19/100], Train Loss: 0.2512, Valid Loss: 0.2537\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004]\n",
      "Epoch [20/100], Train Loss: 0.2504, Valid Loss: 0.2525\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759]\n",
      "Epoch [21/100], Train Loss: 0.2499, Valid Loss: 0.2525\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881]\n",
      "Epoch [22/100], Train Loss: 0.2490, Valid Loss: 0.2511\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554]\n",
      "Epoch [23/100], Train Loss: 0.2479, Valid Loss: 0.2510\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726]\n",
      "Epoch [24/100], Train Loss: 0.2476, Valid Loss: 0.2493\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266]\n",
      "Epoch [25/100], Train Loss: 0.2468, Valid Loss: 0.2493\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387]\n",
      "Epoch [26/100], Train Loss: 0.2460, Valid Loss: 0.2492\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752]\n",
      "Epoch [27/100], Train Loss: 0.2457, Valid Loss: 0.2497\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362]\n",
      "Epoch [28/100], Train Loss: 0.2454, Valid Loss: 0.2488\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692]\n",
      "Epoch [29/100], Train Loss: 0.2448, Valid Loss: 0.2483\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496]\n",
      "Epoch [30/100], Train Loss: 0.2447, Valid Loss: 0.2476\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658]\n",
      "Epoch [31/100], Train Loss: 0.2444, Valid Loss: 0.2476\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666]\n",
      "Epoch [32/100], Train Loss: 0.2437, Valid Loss: 0.2464\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765]\n",
      "Epoch [33/100], Train Loss: 0.2434, Valid Loss: 0.2469\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878]\n",
      "Epoch [34/100], Train Loss: 0.2435, Valid Loss: 0.2469\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893]\n",
      "Epoch [35/100], Train Loss: 0.2435, Valid Loss: 0.2453\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722]\n",
      "Epoch [36/100], Train Loss: 0.2429, Valid Loss: 0.2458\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133]\n",
      "Epoch [37/100], Train Loss: 0.2425, Valid Loss: 0.2456\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689]\n",
      "Epoch [38/100], Train Loss: 0.2422, Valid Loss: 0.2459\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896]\n",
      "Epoch [39/100], Train Loss: 0.2422, Valid Loss: 0.2447\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056]\n",
      "Epoch [40/100], Train Loss: 0.2420, Valid Loss: 0.2440\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839]\n",
      "Epoch [41/100], Train Loss: 0.2409, Valid Loss: 0.2445\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753]\n",
      "Epoch [42/100], Train Loss: 0.2406, Valid Loss: 0.2434\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285]\n",
      "Epoch [43/100], Train Loss: 0.2405, Valid Loss: 0.2432\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883]\n",
      "Epoch [44/100], Train Loss: 0.2405, Valid Loss: 0.2429\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132]\n",
      "Epoch [45/100], Train Loss: 0.2404, Valid Loss: 0.2422\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735]\n",
      "Epoch [46/100], Train Loss: 0.2400, Valid Loss: 0.2423\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798]\n",
      "Epoch [47/100], Train Loss: 0.2402, Valid Loss: 0.2431\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422]\n",
      "Epoch [48/100], Train Loss: 0.2395, Valid Loss: 0.2434\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863]\n",
      "Epoch [49/100], Train Loss: 0.2391, Valid Loss: 0.2421\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487]\n",
      "Epoch [50/100], Train Loss: 0.2386, Valid Loss: 0.2415\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569]\n",
      "Epoch [51/100], Train Loss: 0.2389, Valid Loss: 0.2426\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046]\n",
      "Epoch [52/100], Train Loss: 0.2388, Valid Loss: 0.2419\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326]\n",
      "Epoch [53/100], Train Loss: 0.2385, Valid Loss: 0.2415\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436, 0.23850670664370816]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326, 0.24151446856558323]\n",
      "Epoch [54/100], Train Loss: 0.2383, Valid Loss: 0.2402\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436, 0.23850670664370816, 0.238327650518357]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326, 0.24151446856558323, 0.24015007615089418]\n",
      "Epoch [55/100], Train Loss: 0.2381, Valid Loss: 0.2401\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436, 0.23850670664370816, 0.238327650518357, 0.2380629366711725]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326, 0.24151446856558323, 0.24015007615089418, 0.2400966539978981]\n",
      "Epoch [56/100], Train Loss: 0.2376, Valid Loss: 0.2400\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436, 0.23850670664370816, 0.238327650518357, 0.2380629366711725, 0.23759155909094629]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326, 0.24151446856558323, 0.24015007615089418, 0.2400966539978981, 0.24000595286488532]\n",
      "Epoch [57/100], Train Loss: 0.2373, Valid Loss: 0.2412\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436, 0.23850670664370816, 0.238327650518357, 0.2380629366711725, 0.23759155909094629, 0.23734953084701224]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326, 0.24151446856558323, 0.24015007615089418, 0.2400966539978981, 0.24000595286488532, 0.24122143685817718]\n",
      "Epoch [58/100], Train Loss: 0.2374, Valid Loss: 0.2400\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436, 0.23850670664370816, 0.238327650518357, 0.2380629366711725, 0.23759155909094629, 0.23734953084701224, 0.23742508916537972]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326, 0.24151446856558323, 0.24015007615089418, 0.2400966539978981, 0.24000595286488532, 0.24122143685817718, 0.2400262676179409]\n",
      "Epoch [59/100], Train Loss: 0.2373, Valid Loss: 0.2398\n",
      "loss_train:  [0.9191135364242747, 0.5370767999298965, 0.4009127979037128, 0.33762622634066813, 0.30542705877672266, 0.28788138114953343, 0.2780422240118437, 0.2713513147981861, 0.26764316875723343, 0.26418802189298823, 0.2619044294085684, 0.2604767092609707, 0.25913461014817035, 0.25719590437940404, 0.25600830456124074, 0.25489462874358215, 0.25329519940327994, 0.2522012481017958, 0.2512247933051254, 0.2503553905253169, 0.24992543383489682, 0.24897713525385795, 0.24792641429584236, 0.247635525332976, 0.24676639266029188, 0.24599180993022798, 0.24573311313420912, 0.2454192528053175, 0.24478769943683962, 0.24472186761566356, 0.24440127620591393, 0.24368036236566834, 0.24343205403678025, 0.24349142714769026, 0.24346280918468402, 0.2428531310980833, 0.24249512598484377, 0.24221811943416355, 0.24219286819047567, 0.24195803522686415, 0.24091829651895957, 0.24062897887410997, 0.24048200032756298, 0.24045757091120828, 0.24037281055993673, 0.24000327458864526, 0.24020464614599565, 0.2395022137066986, 0.23909723504057415, 0.2386397181809703, 0.23887705850073054, 0.2387569901309436, 0.23850670664370816, 0.238327650518357, 0.2380629366711725, 0.23759155909094629, 0.23734953084701224, 0.23742508916537972, 0.2373227133781095]\n",
      "vaild_train:  [0.6238858565688133, 0.43380031511187556, 0.34909494817256925, 0.3101947419345379, 0.2911496706306934, 0.28062036260962486, 0.2755269005894661, 0.2710545688867569, 0.2676031216979027, 0.2651794634759426, 0.26468744575977327, 0.2615834027528763, 0.2601267397403717, 0.2585090138018131, 0.25845566056668756, 0.256967817991972, 0.2557357706129551, 0.25406563840806484, 0.25368447676301004, 0.2524999316781759, 0.2525314372032881, 0.25107221603393554, 0.25099402740597726, 0.2493013359606266, 0.24927545227110387, 0.24924992322921752, 0.24967996627092362, 0.24884070567786692, 0.24834236465394496, 0.24758876897394658, 0.24763713628053666, 0.24643770195543765, 0.24687798023223878, 0.24688268788158893, 0.24534959830343722, 0.2457573737949133, 0.24558552168309689, 0.24586182832717896, 0.24467968866229056, 0.2440344925969839, 0.24448818266391753, 0.24340158589184285, 0.24315109178423883, 0.24285962730646132, 0.24217834286391735, 0.242315361648798, 0.24309868663549422, 0.24336805753409863, 0.24212406687438487, 0.241513679176569, 0.24259419478476046, 0.24185874983668326, 0.24151446856558323, 0.24015007615089418, 0.2400966539978981, 0.24000595286488532, 0.24122143685817718, 0.2400262676179409, 0.239823018014431]\n",
      "Epoch [60/100], Train Loss: 0.2375, Valid Loss: 0.2397\n",
      "Early stopped at epoch 59, train loss stop improving\n",
      "Training finished\n",
      "87.9535436630249\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "es_cnt = 0\n",
    "es_thres = 5\n",
    "prev_train_loss = float('inf')\n",
    "loss_train = []\n",
    "loss_vaild = []\n",
    "num_epochs = 100 # 总训练轮数\n",
    "#num_batch_train = 0\n",
    "for epoch in range(num_epochs):\n",
    "  #train_bar = tqdm(train_loader)\n",
    "  train_loss = 0.0\n",
    "  \n",
    "  for i , (batch) in enumerate(train_loader):\n",
    "\n",
    "    # 数据转到device\n",
    "    train_batch = batch[0].to(device)\n",
    "    \n",
    "    # 训练步骤  \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_batch)\n",
    "    loss = criterion(outputs, train_batch)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    #num_batch_train +=1\n",
    "  #train_loss除以所有bacth个数\n",
    "  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "  loss_train.append(train_loss)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  # 验证\n",
    "  valid_loss = 0.0\n",
    "  #num_batch_vaild = 0\n",
    "  with torch.no_grad():\n",
    "    for i , (batch) in enumerate(vaild_loader):\n",
    "    #for batch in vaild_loader:\n",
    "    \n",
    "      val_batch = batch[0].to(device)\n",
    "      \n",
    "      outputs = model(val_batch)\n",
    "      loss = criterion(outputs, val_batch)\n",
    "      valid_loss += loss.item()\n",
    "      #num_batch_vaild += 1\n",
    "    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "    loss_vaild.append(valid_loss)\n",
    "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "\n",
    "    \n",
    "    # Early stopping\n",
    "    if train_loss - prev_train_loss >= 0:\n",
    "        es_cnt += 1\n",
    "    else:\n",
    "        #es_cnt = 0\n",
    "        pass\n",
    "\n",
    "    if es_cnt >= es_thres:\n",
    "        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "        break  \n",
    "\n",
    "    prev_train_loss = train_loss\n",
    "  print('loss_train: ', loss_train)\n",
    "  print('vaild_train: ',loss_vaild)          \n",
    "print(\"Training finished\")\n",
    "current_time = time.time()\n",
    "time_sum = current_time-start_time\n",
    "print(time_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = pd.DataFrame(loss_train)\n",
    "loss_vaild = pd.DataFrame(loss_vaild)\n",
    "\n",
    "loss = pd.concat([loss_train,loss_vaild],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.columns = ['train_loss','vaild_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r'.\\model_3dreal2patch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12584, 1728])\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(w1*w2*w3,w1*w2*w3).to(device)\n",
    "data = data.to(device)\n",
    "model.load_state_dict(torch.load(r'.\\model_3dreal2patch.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "    #loss = criterion(output, data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.cpu()\n",
    "output = output.numpy()\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to_csv(r'loss_3dreal2patch.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r'./output_3dreal2patch.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_0 = []\n",
    "#start_time = time.time()\n",
    "#es_cnt = 0\n",
    "#es_thres = 5\n",
    "#prev_train_loss = float('inf')\n",
    "#loss_train = []\n",
    "#loss_vaild = []\n",
    "#num_epochs = 100 # 总训练轮数\n",
    "##num_batch_train = 0\n",
    "#for epoch in range(num_epochs):\n",
    "#  #train_bar = tqdm(train_loader)\n",
    "#  train_loss = 0.0\n",
    "#  \n",
    "#  for i , (batch) in enumerate(train_loader):\n",
    "#\n",
    "#    # 数据转到device\n",
    "#    train_batch = batch[0].to(device)\n",
    "#    \n",
    "#    # 训练步骤  \n",
    "#    optimizer.zero_grad()\n",
    "#    outputs = model(train_batch)\n",
    "#    loss = criterion(outputs, train_batch)\n",
    "#    loss.backward() \n",
    "#    optimizer.step()\n",
    "#\n",
    "#    loss_0.append(loss.item())\n",
    "#\n",
    "#    train_loss += loss.item()\n",
    "#    #num_batch_train +=1\n",
    "#  #train_loss除以所有bacth个数\n",
    "#  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "#  loss_train.append(train_loss)\n",
    "#    \n",
    "#\n",
    "#\n",
    "#\n",
    "#  # 验证\n",
    "#  valid_loss = 0.0\n",
    "#  #num_batch_vaild = 0\n",
    "#  with torch.no_grad():\n",
    "#    for i , (batch) in enumerate(vaild_loader):\n",
    "#    #for batch in vaild_loader:\n",
    "#    \n",
    "#      val_batch = batch[0].to(device)\n",
    "#      \n",
    "#      outputs = model(val_batch)\n",
    "#      loss = criterion(outputs, val_batch)\n",
    "#      valid_loss += loss.item()\n",
    "#      #num_batch_vaild += 1\n",
    "#    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "#    loss_vaild.append(valid_loss)\n",
    "#    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "#\n",
    "#    \n",
    "#    # Early stopping\n",
    "#    if train_loss - prev_train_loss >= 0:\n",
    "#        es_cnt += 1\n",
    "#    else:\n",
    "#        #es_cnt = 0\n",
    "#        pass\n",
    "#\n",
    "#    if es_cnt >= es_thres:\n",
    "#        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "#        break  \n",
    "#    \n",
    "#\n",
    "#\n",
    "##   if epoch == 10:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs10.pth')\n",
    "##   elif epoch == 20:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs20.pth')\n",
    "##   elif epoch == 30:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs30.pth')\n",
    "##   elif epoch == 40:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs40.pth')\n",
    "##   elif epoch == 50:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs50.pth')\n",
    "##   elif epoch == 60:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs60.pth')\n",
    "##   elif epoch == 70:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs70.pth')\n",
    "##   elif epoch == 80:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs80.pth')\n",
    "##   elif epoch == 90:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs90.pth')\n",
    "##   elif epoch == 100:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs100.pth')\n",
    "##   else:\n",
    "##       pass\n",
    "#\n",
    "#    prev_train_loss = train_loss\n",
    "#  print('loss_train: ', loss_train)\n",
    "#  print('vaild_train: ',loss_vaild)          \n",
    "#print(\"Training finished\")\n",
    "#current_time = time.time()\n",
    "#time_sum = current_time-start_time\n",
    "#print(time_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
