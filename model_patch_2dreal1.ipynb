{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import tushare as ts\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_noisy = r'Input_Patches_2Dreal1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_noisy, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.162368</td>\n",
       "      <td>0.219258</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.198699</td>\n",
       "      <td>0.493524</td>\n",
       "      <td>0.245892</td>\n",
       "      <td>-0.182372</td>\n",
       "      <td>-0.156646</td>\n",
       "      <td>-0.316870</td>\n",
       "      <td>0.224624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>-0.073450</td>\n",
       "      <td>0.230653</td>\n",
       "      <td>0.186483</td>\n",
       "      <td>-0.103519</td>\n",
       "      <td>-0.055073</td>\n",
       "      <td>-0.205587</td>\n",
       "      <td>0.169509</td>\n",
       "      <td>-0.052408</td>\n",
       "      <td>-0.188393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.711692</td>\n",
       "      <td>-0.265535</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.240719</td>\n",
       "      <td>-0.671804</td>\n",
       "      <td>-0.229972</td>\n",
       "      <td>0.583406</td>\n",
       "      <td>0.595760</td>\n",
       "      <td>0.279998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407242</td>\n",
       "      <td>0.028367</td>\n",
       "      <td>-0.164915</td>\n",
       "      <td>-0.394898</td>\n",
       "      <td>-0.529706</td>\n",
       "      <td>-0.045514</td>\n",
       "      <td>-0.076049</td>\n",
       "      <td>-0.047949</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>0.003718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.023045</td>\n",
       "      <td>-0.031333</td>\n",
       "      <td>0.190656</td>\n",
       "      <td>-0.153333</td>\n",
       "      <td>-0.318722</td>\n",
       "      <td>-0.327969</td>\n",
       "      <td>-0.852523</td>\n",
       "      <td>-0.108784</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>0.301851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165481</td>\n",
       "      <td>-0.253374</td>\n",
       "      <td>-0.419997</td>\n",
       "      <td>-0.117057</td>\n",
       "      <td>-0.117169</td>\n",
       "      <td>-0.098420</td>\n",
       "      <td>0.363498</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.243335</td>\n",
       "      <td>0.157551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.177922</td>\n",
       "      <td>-0.266030</td>\n",
       "      <td>-0.141247</td>\n",
       "      <td>0.487962</td>\n",
       "      <td>0.602046</td>\n",
       "      <td>0.296484</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>-0.300288</td>\n",
       "      <td>-0.482048</td>\n",
       "      <td>0.086826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239414</td>\n",
       "      <td>0.120151</td>\n",
       "      <td>0.163402</td>\n",
       "      <td>-0.273804</td>\n",
       "      <td>0.028751</td>\n",
       "      <td>0.531286</td>\n",
       "      <td>0.170631</td>\n",
       "      <td>0.200496</td>\n",
       "      <td>0.022241</td>\n",
       "      <td>-0.191563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176998</td>\n",
       "      <td>-0.079739</td>\n",
       "      <td>-0.257229</td>\n",
       "      <td>-0.217703</td>\n",
       "      <td>0.026047</td>\n",
       "      <td>0.226468</td>\n",
       "      <td>0.019902</td>\n",
       "      <td>-0.084082</td>\n",
       "      <td>0.066048</td>\n",
       "      <td>0.049374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048834</td>\n",
       "      <td>0.037723</td>\n",
       "      <td>0.456958</td>\n",
       "      <td>0.254121</td>\n",
       "      <td>0.387824</td>\n",
       "      <td>0.171179</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.123482</td>\n",
       "      <td>-0.141251</td>\n",
       "      <td>-0.289645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>0.135708</td>\n",
       "      <td>-0.175223</td>\n",
       "      <td>-0.155916</td>\n",
       "      <td>0.110586</td>\n",
       "      <td>-0.101674</td>\n",
       "      <td>-0.305425</td>\n",
       "      <td>-0.304724</td>\n",
       "      <td>-0.350010</td>\n",
       "      <td>-0.216762</td>\n",
       "      <td>0.217116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087081</td>\n",
       "      <td>0.034378</td>\n",
       "      <td>0.054869</td>\n",
       "      <td>-0.010448</td>\n",
       "      <td>-0.081313</td>\n",
       "      <td>-0.077376</td>\n",
       "      <td>0.238562</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.283365</td>\n",
       "      <td>0.169007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27952</th>\n",
       "      <td>-0.106156</td>\n",
       "      <td>-0.003215</td>\n",
       "      <td>-0.538261</td>\n",
       "      <td>0.026924</td>\n",
       "      <td>-0.765845</td>\n",
       "      <td>-0.459111</td>\n",
       "      <td>-2.698122</td>\n",
       "      <td>-0.538279</td>\n",
       "      <td>-0.157002</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105604</td>\n",
       "      <td>-0.352210</td>\n",
       "      <td>0.031722</td>\n",
       "      <td>0.339139</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>-0.014568</td>\n",
       "      <td>-0.191193</td>\n",
       "      <td>0.067487</td>\n",
       "      <td>-0.060864</td>\n",
       "      <td>-0.162643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27953</th>\n",
       "      <td>0.048989</td>\n",
       "      <td>-0.056892</td>\n",
       "      <td>0.095801</td>\n",
       "      <td>-0.062812</td>\n",
       "      <td>-0.209297</td>\n",
       "      <td>0.077618</td>\n",
       "      <td>-0.220826</td>\n",
       "      <td>-0.194618</td>\n",
       "      <td>-0.324122</td>\n",
       "      <td>0.254190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362360</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>0.189344</td>\n",
       "      <td>-0.290240</td>\n",
       "      <td>0.434496</td>\n",
       "      <td>-0.103193</td>\n",
       "      <td>0.157770</td>\n",
       "      <td>0.663759</td>\n",
       "      <td>-0.059527</td>\n",
       "      <td>-0.308712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27954</th>\n",
       "      <td>0.075517</td>\n",
       "      <td>0.180355</td>\n",
       "      <td>0.128823</td>\n",
       "      <td>-0.116407</td>\n",
       "      <td>-0.018621</td>\n",
       "      <td>0.144102</td>\n",
       "      <td>-0.168198</td>\n",
       "      <td>-0.218335</td>\n",
       "      <td>-0.098015</td>\n",
       "      <td>0.132025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111506</td>\n",
       "      <td>0.284856</td>\n",
       "      <td>-0.038512</td>\n",
       "      <td>0.511344</td>\n",
       "      <td>0.274927</td>\n",
       "      <td>0.057396</td>\n",
       "      <td>0.040645</td>\n",
       "      <td>-0.143664</td>\n",
       "      <td>0.490805</td>\n",
       "      <td>0.276644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27955</th>\n",
       "      <td>-0.033214</td>\n",
       "      <td>0.158762</td>\n",
       "      <td>-0.057984</td>\n",
       "      <td>0.290792</td>\n",
       "      <td>-0.016150</td>\n",
       "      <td>0.018415</td>\n",
       "      <td>-0.394698</td>\n",
       "      <td>0.196743</td>\n",
       "      <td>0.199372</td>\n",
       "      <td>0.421203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27956 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0     -0.162368  0.219258  0.009214  0.198699  0.493524  0.245892 -0.182372   \n",
       "1     -0.711692 -0.265535  0.404216 -0.017491 -0.240719 -0.671804 -0.229972   \n",
       "2     -0.023045 -0.031333  0.190656 -0.153333 -0.318722 -0.327969 -0.852523   \n",
       "3     -0.177922 -0.266030 -0.141247  0.487962  0.602046  0.296484  0.342437   \n",
       "4      0.176998 -0.079739 -0.257229 -0.217703  0.026047  0.226468  0.019902   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "27951  0.135708 -0.175223 -0.155916  0.110586 -0.101674 -0.305425 -0.304724   \n",
       "27952 -0.106156 -0.003215 -0.538261  0.026924 -0.765845 -0.459111 -2.698122   \n",
       "27953  0.048989 -0.056892  0.095801 -0.062812 -0.209297  0.077618 -0.220826   \n",
       "27954  0.075517  0.180355  0.128823 -0.116407 -0.018621  0.144102 -0.168198   \n",
       "27955 -0.033214  0.158762 -0.057984  0.290792 -0.016150  0.018415 -0.394698   \n",
       "\n",
       "           7         8         9     ...      1014      1015      1016  \\\n",
       "0     -0.156646 -0.316870  0.224624  ...  0.038849 -0.073450  0.230653   \n",
       "1      0.583406  0.595760  0.279998  ...  0.407242  0.028367 -0.164915   \n",
       "2     -0.108784  0.031883  0.301851  ...  0.165481 -0.253374 -0.419997   \n",
       "3     -0.300288 -0.482048  0.086826  ... -0.239414  0.120151  0.163402   \n",
       "4     -0.084082  0.066048  0.049374  ...  0.048834  0.037723  0.456958   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "27951 -0.350010 -0.216762  0.217116  ... -0.087081  0.034378  0.054869   \n",
       "27952 -0.538279 -0.157002 -0.002314  ...  0.105604 -0.352210  0.031722   \n",
       "27953 -0.194618 -0.324122  0.254190  ... -0.362360  0.030006  0.189344   \n",
       "27954 -0.218335 -0.098015  0.132025  ...  0.111506  0.284856 -0.038512   \n",
       "27955  0.196743  0.199372  0.421203  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "           1017      1018      1019      1020      1021      1022      1023  \n",
       "0      0.186483 -0.103519 -0.055073 -0.205587  0.169509 -0.052408 -0.188393  \n",
       "1     -0.394898 -0.529706 -0.045514 -0.076049 -0.047949  0.080052  0.003718  \n",
       "2     -0.117057 -0.117169 -0.098420  0.363498  0.042636  0.243335  0.157551  \n",
       "3     -0.273804  0.028751  0.531286  0.170631  0.200496  0.022241 -0.191563  \n",
       "4      0.254121  0.387824  0.171179  0.337118  0.123482 -0.141251 -0.289645  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "27951 -0.010448 -0.081313 -0.077376  0.238562  0.109800  0.283365  0.169007  \n",
       "27952  0.339139  0.016016 -0.014568 -0.191193  0.067487 -0.060864 -0.162643  \n",
       "27953 -0.290240  0.434496 -0.103193  0.157770  0.663759 -0.059527 -0.308712  \n",
       "27954  0.511344  0.274927  0.057396  0.040645 -0.143664  0.490805  0.276644  \n",
       "27955  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[27956 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)\n",
    "data= torch.from_numpy(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27956, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22364, 1024])\n",
      "torch.Size([5592, 1024])\n"
     ]
    }
   ],
   "source": [
    "#将前80%作为训练集，后20%作为测试集\n",
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "vaild = data[train_size:]\n",
    "print(train.shape)\n",
    "print(vaild.shape)\n",
    "batch_size1 = 64\n",
    "w1 = 32\n",
    "w2 = 32\n",
    "\n",
    "train_data= TensorDataset(train)\n",
    "vaild_data= TensorDataset(vaild)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size = 64,\n",
    "                                           shuffle = True)\n",
    "\n",
    "vaild_loader = torch.utils.data.DataLoader(vaild_data,\n",
    "                                          batch_size = 64,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Fully connected (FC) block\n",
    "class FCB(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.bn = nn.BatchNorm1d(output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.fcb0 = FCB(input_size, 128, dropout)\n",
    "        self.fcb1 = FCB(128, 64, dropout)\n",
    "\n",
    "        self.fcb2 = FCB(64, 32, dropout)\n",
    "\n",
    "        self.fcb3 = FCB(32, 16, dropout)\n",
    "\n",
    "        self.fcb4 = FCB(16, 8, dropout)\n",
    "\n",
    "        self.fcb5 = FCB(8, 4, dropout)\n",
    "\n",
    "        self.fcb6 = FCB(4, 4, dropout)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = x.reshape(x.shape[0],1,x.shape[1])\n",
    "\n",
    "        x1 = self.fcb0(x)#x->128\n",
    "        x2 = self.fcb1(x1)\n",
    "\n",
    "        x3 = self.fcb2(x2)\n",
    "\n",
    "        x4 = self.fcb3(x3)\n",
    "\n",
    "        x5 = self.fcb4(x4)\n",
    "\n",
    "        x6 = self.fcb5(x5)\n",
    "\n",
    "        x7 = self.fcb6(x6)\n",
    "\n",
    "        x8 = self.fcb6(x7)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        return x2,x3,x4,x5,x6,x7,x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pab1 = FCB(8, 8, dropout)\n",
    "        self.pab2 = FCB(16, 16, dropout)\n",
    "        self.pab3 = FCB(32, 32, dropout)\n",
    "        self.pab4 = FCB(64, 64, dropout)\n",
    "        self.pab5 = FCB(128, 128, dropout)\n",
    "        self.pab6 = FCB(128, output_size, dropout)\n",
    "\n",
    "        self.activation = nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self,x2, x3,x4,x5,x6,x7,x8):\n",
    "        \n",
    "        x = torch.cat((x6,x8),dim=1)\n",
    "        x = self.pab1(x)\n",
    "        x = torch.cat((x,x5),dim=1)\n",
    "        x = self.pab2(x)\n",
    "        x = torch.cat((x,x4),dim=1)\n",
    "        x = self.pab3(x)\n",
    "        x = torch.cat((x,x3),dim=1)\n",
    "        x = self.pab4(x)\n",
    "        x = torch.cat((x,x2),dim=1)\n",
    "        x = self.pab5(x)\n",
    "        x = self.pab6(x)\n",
    "\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size)\n",
    "        self.decoder = Decoder(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2, x3,x4,x5,x6,x7,x8= self.encoder(x)\n",
    "        x = self.decoder(x2, x3,x4,x5,x6,x7,x8)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "model = AutoEncoder(w1*w2,w1*w2).to(device)\n",
    "#将模型转移到GPU上\n",
    "#criterion = MeanHuberLoss(delta=1.3)\n",
    "#criterion = WelschLoss(delta=0.5)\n",
    "#criterion = Loss0(delta=0.46,r=0.05)#0.5 and 0.2,SNR:-8dB ok\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.8045, Valid Loss: 0.5527\n",
      "loss_train:  [0.8044639311517988]\n",
      "vaild_train:  [0.5526764386079528]\n",
      "Epoch [2/100], Train Loss: 0.3638, Valid Loss: 0.2724\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173]\n",
      "Epoch [3/100], Train Loss: 0.1957, Valid Loss: 0.1605\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532]\n",
      "Epoch [4/100], Train Loss: 0.1444, Valid Loss: 0.1235\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357]\n",
      "Epoch [5/100], Train Loss: 0.1323, Valid Loss: 0.1125\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553]\n",
      "Epoch [6/100], Train Loss: 0.1292, Valid Loss: 0.1091\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865]\n",
      "Epoch [7/100], Train Loss: 0.1277, Valid Loss: 0.1083\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644]\n",
      "Epoch [8/100], Train Loss: 0.1266, Valid Loss: 0.1079\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337]\n",
      "Epoch [9/100], Train Loss: 0.1255, Valid Loss: 0.1074\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701]\n",
      "Epoch [10/100], Train Loss: 0.1244, Valid Loss: 0.1073\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291]\n",
      "Epoch [11/100], Train Loss: 0.1235, Valid Loss: 0.1070\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349]\n",
      "Epoch [12/100], Train Loss: 0.1227, Valid Loss: 0.1069\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136]\n",
      "Epoch [13/100], Train Loss: 0.1219, Valid Loss: 0.1069\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317]\n",
      "Epoch [14/100], Train Loss: 0.1214, Valid Loss: 0.1065\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295]\n",
      "Epoch [15/100], Train Loss: 0.1210, Valid Loss: 0.1062\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422]\n",
      "Epoch [16/100], Train Loss: 0.1205, Valid Loss: 0.1065\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211]\n",
      "Epoch [17/100], Train Loss: 0.1202, Valid Loss: 0.1060\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498]\n",
      "Epoch [18/100], Train Loss: 0.1198, Valid Loss: 0.1061\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521]\n",
      "Epoch [19/100], Train Loss: 0.1196, Valid Loss: 0.1059\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007]\n",
      "Epoch [20/100], Train Loss: 0.1193, Valid Loss: 0.1059\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481]\n",
      "Epoch [21/100], Train Loss: 0.1190, Valid Loss: 0.1061\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727]\n",
      "Epoch [22/100], Train Loss: 0.1188, Valid Loss: 0.1063\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551]\n",
      "Epoch [23/100], Train Loss: 0.1185, Valid Loss: 0.1058\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798]\n",
      "Epoch [24/100], Train Loss: 0.1183, Valid Loss: 0.1058\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982]\n",
      "Epoch [25/100], Train Loss: 0.1180, Valid Loss: 0.1060\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144]\n",
      "Epoch [26/100], Train Loss: 0.1178, Valid Loss: 0.1055\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741]\n",
      "Epoch [27/100], Train Loss: 0.1175, Valid Loss: 0.1054\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498]\n",
      "Epoch [28/100], Train Loss: 0.1173, Valid Loss: 0.1058\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092]\n",
      "Epoch [29/100], Train Loss: 0.1171, Valid Loss: 0.1059\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694]\n",
      "Epoch [30/100], Train Loss: 0.1168, Valid Loss: 0.1053\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528]\n",
      "Epoch [31/100], Train Loss: 0.1166, Valid Loss: 0.1057\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764]\n",
      "Epoch [32/100], Train Loss: 0.1166, Valid Loss: 0.1052\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807]\n",
      "Epoch [33/100], Train Loss: 0.1165, Valid Loss: 0.1055\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783]\n",
      "Epoch [34/100], Train Loss: 0.1164, Valid Loss: 0.1052\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236]\n",
      "Epoch [35/100], Train Loss: 0.1163, Valid Loss: 0.1057\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282]\n",
      "Epoch [36/100], Train Loss: 0.1162, Valid Loss: 0.1051\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395]\n",
      "Epoch [37/100], Train Loss: 0.1161, Valid Loss: 0.1052\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228]\n",
      "Epoch [38/100], Train Loss: 0.1160, Valid Loss: 0.1051\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177]\n",
      "Epoch [39/100], Train Loss: 0.1160, Valid Loss: 0.1052\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627]\n",
      "Epoch [40/100], Train Loss: 0.1159, Valid Loss: 0.1053\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227]\n",
      "Epoch [41/100], Train Loss: 0.1158, Valid Loss: 0.1056\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648]\n",
      "Epoch [42/100], Train Loss: 0.1158, Valid Loss: 0.1050\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733]\n",
      "Epoch [43/100], Train Loss: 0.1159, Valid Loss: 0.1049\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907]\n",
      "Epoch [44/100], Train Loss: 0.1158, Valid Loss: 0.1052\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336]\n",
      "Epoch [45/100], Train Loss: 0.1158, Valid Loss: 0.1053\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653]\n",
      "Epoch [46/100], Train Loss: 0.1157, Valid Loss: 0.1054\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676]\n",
      "Epoch [47/100], Train Loss: 0.1157, Valid Loss: 0.1052\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887]\n",
      "Epoch [48/100], Train Loss: 0.1157, Valid Loss: 0.1051\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385, 0.11573329467858587]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887, 0.10513648255304857]\n",
      "Epoch [49/100], Train Loss: 0.1157, Valid Loss: 0.1051\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385, 0.11573329467858587, 0.11571614239897046]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887, 0.10513648255304857, 0.10507610380988229]\n",
      "Epoch [50/100], Train Loss: 0.1157, Valid Loss: 0.1047\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385, 0.11573329467858587, 0.11571614239897046, 0.11566243569765772]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887, 0.10513648255304857, 0.10507610380988229, 0.10465700729665431]\n",
      "Epoch [51/100], Train Loss: 0.1156, Valid Loss: 0.1052\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385, 0.11573329467858587, 0.11571614239897046, 0.11566243569765772, 0.11559063302619117]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887, 0.10513648255304857, 0.10507610380988229, 0.10465700729665431, 0.10519977819851854]\n",
      "Epoch [52/100], Train Loss: 0.1157, Valid Loss: 0.1054\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385, 0.11573329467858587, 0.11571614239897046, 0.11566243569765772, 0.11559063302619117, 0.11566086077264377]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887, 0.10513648255304857, 0.10507610380988229, 0.10465700729665431, 0.10519977819851854, 0.10536718944256956]\n",
      "Epoch [53/100], Train Loss: 0.1156, Valid Loss: 0.1049\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385, 0.11573329467858587, 0.11571614239897046, 0.11566243569765772, 0.11559063302619117, 0.11566086077264377, 0.1155854959998812]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887, 0.10513648255304857, 0.10507610380988229, 0.10465700729665431, 0.10519977819851854, 0.10536718944256956, 0.10491062167354605]\n",
      "Epoch [54/100], Train Loss: 0.1155, Valid Loss: 0.1051\n",
      "loss_train:  [0.8044639311517988, 0.3638168154018266, 0.1956858733722142, 0.1444166673081262, 0.1322598226581301, 0.12916893267205784, 0.12771825409361295, 0.12657262421080046, 0.12549314675586565, 0.12440425851515362, 0.12353638597897121, 0.12273233094385692, 0.12192509853414127, 0.12142657871757234, 0.12096917041710445, 0.12050746921982083, 0.12018644616007805, 0.1198394632765225, 0.11955210064138685, 0.11933330335787365, 0.1189783343247005, 0.11880830756255559, 0.11850692870361465, 0.11825518199375698, 0.11798706897667476, 0.11775810971856117, 0.1174727289378643, 0.11725546268480165, 0.11705621972680091, 0.1168401620217732, 0.11662068690572466, 0.11659959837794304, 0.11647491457206863, 0.11636323545660292, 0.11629121177962848, 0.11617299854755402, 0.11610343752162797, 0.11602802700230054, 0.1159615401497909, 0.11592280451740537, 0.11584383300372532, 0.11581885744418417, 0.11585207113197872, 0.1157607423407691, 0.11579462225948062, 0.11573685997298785, 0.11574434678469385, 0.11573329467858587, 0.11571614239897046, 0.11566243569765772, 0.11559063302619117, 0.11566086077264377, 0.1155854959998812, 0.11548916218536241]\n",
      "vaild_train:  [0.5526764386079528, 0.27239029007879173, 0.16050851378928532, 0.12354262731969357, 0.11251761654222553, 0.1091485254635865, 0.10828763847662644, 0.1079068523408337, 0.1074380882253701, 0.1072870223698291, 0.10697581381960349, 0.10688592806797136, 0.10685119219124317, 0.10654262656515295, 0.10621981085701422, 0.10652954732491211, 0.10601871867071498, 0.10606388798491521, 0.10589218148115007, 0.10589879632673481, 0.106098847463727, 0.10627409358593551, 0.1057547838003798, 0.10578865185379982, 0.10596411844546144, 0.10553290170024741, 0.10544636515392498, 0.10580044934018092, 0.10593949038196694, 0.1052638790993528, 0.10568801999430764, 0.10524295312775807, 0.10545717738568783, 0.10519054980779236, 0.10565585363656282, 0.1050667700950395, 0.10519018278203228, 0.10514680854976177, 0.10515438485890627, 0.10529851185327227, 0.1055755562741648, 0.10499155817722733, 0.10486782452260907, 0.10515025512061336, 0.10532148309390653, 0.10536450503224676, 0.10515285994518887, 0.10513648255304857, 0.10507610380988229, 0.10465700729665431, 0.10519977819851854, 0.10536718944256956, 0.10491062167354605, 0.10511122686280445]\n",
      "Epoch [55/100], Train Loss: 0.1156, Valid Loss: 0.1051\n",
      "Early stopped at epoch 54, train loss stop improving\n",
      "Training finished\n",
      "154.35560035705566\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "es_cnt = 0\n",
    "es_thres = 5\n",
    "prev_train_loss = float('inf')\n",
    "loss_train = []\n",
    "loss_vaild = []\n",
    "num_epochs = 100 # 总训练轮数\n",
    "#num_batch_train = 0\n",
    "for epoch in range(num_epochs):\n",
    "  #train_bar = tqdm(train_loader)\n",
    "  train_loss = 0.0\n",
    "  \n",
    "  for i , (batch) in enumerate(train_loader):\n",
    "\n",
    "    # 数据转到device\n",
    "    train_batch = batch[0].to(device)\n",
    "    \n",
    "    # 训练步骤  \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_batch)\n",
    "    loss = criterion(outputs, train_batch)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    #num_batch_train +=1\n",
    "  #train_loss除以所有bacth个数\n",
    "  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "  loss_train.append(train_loss)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  # 验证\n",
    "  valid_loss = 0.0\n",
    "  #num_batch_vaild = 0\n",
    "  with torch.no_grad():\n",
    "    for i , (batch) in enumerate(vaild_loader):\n",
    "    #for batch in vaild_loader:\n",
    "    \n",
    "      val_batch = batch[0].to(device)\n",
    "      \n",
    "      outputs = model(val_batch)\n",
    "      loss = criterion(outputs, val_batch)\n",
    "      valid_loss += loss.item()\n",
    "      #num_batch_vaild += 1\n",
    "    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "    loss_vaild.append(valid_loss)\n",
    "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "\n",
    "    \n",
    "    # Early stopping\n",
    "    if train_loss - prev_train_loss >= 0:\n",
    "        es_cnt += 1\n",
    "    else:\n",
    "        #es_cnt = 0\n",
    "        pass\n",
    "\n",
    "    if es_cnt >= es_thres:\n",
    "        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "        break  \n",
    "\n",
    "    prev_train_loss = train_loss\n",
    "  print('loss_train: ', loss_train)\n",
    "  print('vaild_train: ',loss_vaild)          \n",
    "print(\"Training finished\")\n",
    "current_time = time.time()\n",
    "time_sum = current_time-start_time\n",
    "print(time_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = pd.DataFrame(loss_train)\n",
    "loss_vaild = pd.DataFrame(loss_vaild)\n",
    "\n",
    "loss = pd.concat([loss_train,loss_vaild],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.columns = ['train_loss','vaild_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r'.\\model_2dreal1patch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27956, 1024])\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(w1*w2,w1*w2).to(device)\n",
    "data = data.to(device)\n",
    "model.load_state_dict(torch.load(r'.\\model_2dreal1patch.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "    #loss = criterion(output, data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.cpu()\n",
    "output = output.numpy()\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to_csv(r'loss_2dreal1patch.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r'./output_2dreal1patch.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_0 = []\n",
    "#start_time = time.time()\n",
    "#es_cnt = 0\n",
    "#es_thres = 5\n",
    "#prev_train_loss = float('inf')\n",
    "#loss_train = []\n",
    "#loss_vaild = []\n",
    "#num_epochs = 100 # 总训练轮数\n",
    "##num_batch_train = 0\n",
    "#for epoch in range(num_epochs):\n",
    "#  #train_bar = tqdm(train_loader)\n",
    "#  train_loss = 0.0\n",
    "#  \n",
    "#  for i , (batch) in enumerate(train_loader):\n",
    "#\n",
    "#    # 数据转到device\n",
    "#    train_batch = batch[0].to(device)\n",
    "#    \n",
    "#    # 训练步骤  \n",
    "#    optimizer.zero_grad()\n",
    "#    outputs = model(train_batch)\n",
    "#    loss = criterion(outputs, train_batch)\n",
    "#    loss.backward() \n",
    "#    optimizer.step()\n",
    "#\n",
    "#    loss_0.append(loss.item())\n",
    "#\n",
    "#    train_loss += loss.item()\n",
    "#    #num_batch_train +=1\n",
    "#  #train_loss除以所有bacth个数\n",
    "#  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "#  loss_train.append(train_loss)\n",
    "#    \n",
    "#\n",
    "#\n",
    "#\n",
    "#  # 验证\n",
    "#  valid_loss = 0.0\n",
    "#  #num_batch_vaild = 0\n",
    "#  with torch.no_grad():\n",
    "#    for i , (batch) in enumerate(vaild_loader):\n",
    "#    #for batch in vaild_loader:\n",
    "#    \n",
    "#      val_batch = batch[0].to(device)\n",
    "#      \n",
    "#      outputs = model(val_batch)\n",
    "#      loss = criterion(outputs, val_batch)\n",
    "#      valid_loss += loss.item()\n",
    "#      #num_batch_vaild += 1\n",
    "#    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "#    loss_vaild.append(valid_loss)\n",
    "#    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "#\n",
    "#    \n",
    "#    # Early stopping\n",
    "#    if train_loss - prev_train_loss >= 0:\n",
    "#        es_cnt += 1\n",
    "#    else:\n",
    "#        #es_cnt = 0\n",
    "#        pass\n",
    "#\n",
    "#    if es_cnt >= es_thres:\n",
    "#        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "#        break  \n",
    "#    \n",
    "#\n",
    "#\n",
    "##   if epoch == 10:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs10.pth')\n",
    "##   elif epoch == 20:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs20.pth')\n",
    "##   elif epoch == 30:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs30.pth')\n",
    "##   elif epoch == 40:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs40.pth')\n",
    "##   elif epoch == 50:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs50.pth')\n",
    "##   elif epoch == 60:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs60.pth')\n",
    "##   elif epoch == 70:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs70.pth')\n",
    "##   elif epoch == 80:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs80.pth')\n",
    "##   elif epoch == 90:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs90.pth')\n",
    "##   elif epoch == 100:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs100.pth')\n",
    "##   else:\n",
    "##       pass\n",
    "#\n",
    "#    prev_train_loss = train_loss\n",
    "#  print('loss_train: ', loss_train)\n",
    "#  print('vaild_train: ',loss_vaild)          \n",
    "#print(\"Training finished\")\n",
    "#current_time = time.time()\n",
    "#time_sum = current_time-start_time\n",
    "#print(time_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
