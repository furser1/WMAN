{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import tushare as ts\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_noisy = r'Input_Patches_3Dsyn2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_noisy, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1718</th>\n",
       "      <th>1719</th>\n",
       "      <th>1720</th>\n",
       "      <th>1721</th>\n",
       "      <th>1722</th>\n",
       "      <th>1723</th>\n",
       "      <th>1724</th>\n",
       "      <th>1725</th>\n",
       "      <th>1726</th>\n",
       "      <th>1727</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.222543</td>\n",
       "      <td>0.189528</td>\n",
       "      <td>-0.079685</td>\n",
       "      <td>-0.601468</td>\n",
       "      <td>-0.364523</td>\n",
       "      <td>-0.116314</td>\n",
       "      <td>-0.382804</td>\n",
       "      <td>-0.024234</td>\n",
       "      <td>0.120265</td>\n",
       "      <td>0.200890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089436</td>\n",
       "      <td>-0.206247</td>\n",
       "      <td>-0.012145</td>\n",
       "      <td>0.031979</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.332086</td>\n",
       "      <td>-0.048137</td>\n",
       "      <td>0.399868</td>\n",
       "      <td>0.174985</td>\n",
       "      <td>-0.049027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043055</td>\n",
       "      <td>-0.293164</td>\n",
       "      <td>-0.321591</td>\n",
       "      <td>-0.148925</td>\n",
       "      <td>-0.438493</td>\n",
       "      <td>-0.063874</td>\n",
       "      <td>0.118441</td>\n",
       "      <td>-0.126278</td>\n",
       "      <td>0.362018</td>\n",
       "      <td>0.132566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044108</td>\n",
       "      <td>-0.310033</td>\n",
       "      <td>0.427230</td>\n",
       "      <td>-1.286497</td>\n",
       "      <td>-0.276580</td>\n",
       "      <td>-0.520041</td>\n",
       "      <td>0.807820</td>\n",
       "      <td>-0.760938</td>\n",
       "      <td>1.760631</td>\n",
       "      <td>0.488653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.155733</td>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.075974</td>\n",
       "      <td>-0.449269</td>\n",
       "      <td>-0.009123</td>\n",
       "      <td>0.061756</td>\n",
       "      <td>-0.365791</td>\n",
       "      <td>-0.067311</td>\n",
       "      <td>0.357381</td>\n",
       "      <td>0.515759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240191</td>\n",
       "      <td>-0.095355</td>\n",
       "      <td>-0.191619</td>\n",
       "      <td>0.100956</td>\n",
       "      <td>-0.262505</td>\n",
       "      <td>-0.355827</td>\n",
       "      <td>-0.109347</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>-0.029677</td>\n",
       "      <td>0.012212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009747</td>\n",
       "      <td>0.321426</td>\n",
       "      <td>-0.016235</td>\n",
       "      <td>0.021465</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>-0.430391</td>\n",
       "      <td>-0.346896</td>\n",
       "      <td>-0.171349</td>\n",
       "      <td>-0.349497</td>\n",
       "      <td>0.338090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139184</td>\n",
       "      <td>-0.385162</td>\n",
       "      <td>0.037424</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>-0.112325</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>-0.404483</td>\n",
       "      <td>-0.125265</td>\n",
       "      <td>-0.201255</td>\n",
       "      <td>0.015312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309502</td>\n",
       "      <td>-0.680192</td>\n",
       "      <td>-0.729620</td>\n",
       "      <td>-1.760106</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>-0.483123</td>\n",
       "      <td>-0.136336</td>\n",
       "      <td>-0.446910</td>\n",
       "      <td>-0.499735</td>\n",
       "      <td>0.308189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084996</td>\n",
       "      <td>0.448267</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>-0.021542</td>\n",
       "      <td>-0.186922</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.140575</td>\n",
       "      <td>-0.151105</td>\n",
       "      <td>-0.052745</td>\n",
       "      <td>0.099958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50710</th>\n",
       "      <td>0.242076</td>\n",
       "      <td>0.076601</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>-0.163801</td>\n",
       "      <td>-0.139315</td>\n",
       "      <td>-0.047873</td>\n",
       "      <td>0.205326</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>-0.306427</td>\n",
       "      <td>-0.190762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419610</td>\n",
       "      <td>0.449289</td>\n",
       "      <td>-0.063851</td>\n",
       "      <td>-0.005148</td>\n",
       "      <td>-0.048765</td>\n",
       "      <td>-0.149019</td>\n",
       "      <td>0.286533</td>\n",
       "      <td>-0.018275</td>\n",
       "      <td>-0.037540</td>\n",
       "      <td>0.392779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50711</th>\n",
       "      <td>0.451109</td>\n",
       "      <td>0.364099</td>\n",
       "      <td>0.227085</td>\n",
       "      <td>0.243715</td>\n",
       "      <td>-0.304514</td>\n",
       "      <td>-0.040334</td>\n",
       "      <td>-0.073196</td>\n",
       "      <td>-0.164095</td>\n",
       "      <td>-0.250486</td>\n",
       "      <td>0.345374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163986</td>\n",
       "      <td>0.221959</td>\n",
       "      <td>0.073660</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>-0.025043</td>\n",
       "      <td>0.128843</td>\n",
       "      <td>-0.216760</td>\n",
       "      <td>0.502266</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>-0.327360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50712</th>\n",
       "      <td>0.332402</td>\n",
       "      <td>0.736117</td>\n",
       "      <td>0.668807</td>\n",
       "      <td>0.784152</td>\n",
       "      <td>-0.291261</td>\n",
       "      <td>-0.218808</td>\n",
       "      <td>0.105562</td>\n",
       "      <td>-0.128218</td>\n",
       "      <td>0.118664</td>\n",
       "      <td>-0.265187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188547</td>\n",
       "      <td>-0.446252</td>\n",
       "      <td>-0.033322</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>-0.232097</td>\n",
       "      <td>-0.271521</td>\n",
       "      <td>-0.093345</td>\n",
       "      <td>-0.010404</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>-0.623515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50713</th>\n",
       "      <td>-0.088742</td>\n",
       "      <td>0.156048</td>\n",
       "      <td>0.617304</td>\n",
       "      <td>0.725424</td>\n",
       "      <td>0.158205</td>\n",
       "      <td>-0.013956</td>\n",
       "      <td>-0.080057</td>\n",
       "      <td>-0.008036</td>\n",
       "      <td>-0.140840</td>\n",
       "      <td>-0.069499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359485</td>\n",
       "      <td>-0.359113</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>0.014931</td>\n",
       "      <td>0.123114</td>\n",
       "      <td>0.353993</td>\n",
       "      <td>0.144014</td>\n",
       "      <td>-0.107187</td>\n",
       "      <td>-0.246051</td>\n",
       "      <td>0.090739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50714</th>\n",
       "      <td>0.897420</td>\n",
       "      <td>-0.047897</td>\n",
       "      <td>0.077913</td>\n",
       "      <td>-0.927219</td>\n",
       "      <td>-1.069959</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>-0.219285</td>\n",
       "      <td>-0.956328</td>\n",
       "      <td>-0.109426</td>\n",
       "      <td>1.497121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137903</td>\n",
       "      <td>-0.084705</td>\n",
       "      <td>-0.006071</td>\n",
       "      <td>-0.562001</td>\n",
       "      <td>0.066138</td>\n",
       "      <td>0.231651</td>\n",
       "      <td>0.204527</td>\n",
       "      <td>-0.113531</td>\n",
       "      <td>-0.198096</td>\n",
       "      <td>0.177569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50715 rows × 1728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0     -0.222543  0.189528 -0.079685 -0.601468 -0.364523 -0.116314 -0.382804   \n",
       "1      0.043055 -0.293164 -0.321591 -0.148925 -0.438493 -0.063874  0.118441   \n",
       "2     -0.155733  0.207998  0.075974 -0.449269 -0.009123  0.061756 -0.365791   \n",
       "3     -0.009747  0.321426 -0.016235  0.021465 -0.120913 -0.430391 -0.346896   \n",
       "4      0.309502 -0.680192 -0.729620 -1.760106  0.020797 -0.483123 -0.136336   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "50710  0.242076  0.076601  0.092620 -0.163801 -0.139315 -0.047873  0.205326   \n",
       "50711  0.451109  0.364099  0.227085  0.243715 -0.304514 -0.040334 -0.073196   \n",
       "50712  0.332402  0.736117  0.668807  0.784152 -0.291261 -0.218808  0.105562   \n",
       "50713 -0.088742  0.156048  0.617304  0.725424  0.158205 -0.013956 -0.080057   \n",
       "50714  0.897420 -0.047897  0.077913 -0.927219 -1.069959  0.660066 -0.219285   \n",
       "\n",
       "           7         8         9     ...      1718      1719      1720  \\\n",
       "0     -0.024234  0.120265  0.200890  ... -0.089436 -0.206247 -0.012145   \n",
       "1     -0.126278  0.362018  0.132566  ... -0.044108 -0.310033  0.427230   \n",
       "2     -0.067311  0.357381  0.515759  ...  0.240191 -0.095355 -0.191619   \n",
       "3     -0.171349 -0.349497  0.338090  ... -0.139184 -0.385162  0.037424   \n",
       "4     -0.446910 -0.499735  0.308189  ... -0.084996  0.448267  0.032877   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "50710 -0.003199 -0.306427 -0.190762  ...  0.419610  0.449289 -0.063851   \n",
       "50711 -0.164095 -0.250486  0.345374  ... -0.163986  0.221959  0.073660   \n",
       "50712 -0.128218  0.118664 -0.265187  ... -0.188547 -0.446252 -0.033322   \n",
       "50713 -0.008036 -0.140840 -0.069499  ... -0.359485 -0.359113  0.288803   \n",
       "50714 -0.956328 -0.109426  1.497121  ...  0.137903 -0.084705 -0.006071   \n",
       "\n",
       "           1721      1722      1723      1724      1725      1726      1727  \n",
       "0      0.031979 -0.008258 -0.332086 -0.048137  0.399868  0.174985 -0.049027  \n",
       "1     -1.286497 -0.276580 -0.520041  0.807820 -0.760938  1.760631  0.488653  \n",
       "2      0.100956 -0.262505 -0.355827 -0.109347  0.085700 -0.029677  0.012212  \n",
       "3     -0.015406 -0.112325  0.085214 -0.404483 -0.125265 -0.201255  0.015312  \n",
       "4     -0.021542 -0.186922  0.152195  0.140575 -0.151105 -0.052745  0.099958  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "50710 -0.005148 -0.048765 -0.149019  0.286533 -0.018275 -0.037540  0.392779  \n",
       "50711  0.022314 -0.025043  0.128843 -0.216760  0.502266  0.007384 -0.327360  \n",
       "50712  0.010333 -0.232097 -0.271521 -0.093345 -0.010404  0.017806 -0.623515  \n",
       "50713  0.014931  0.123114  0.353993  0.144014 -0.107187 -0.246051  0.090739  \n",
       "50714 -0.562001  0.066138  0.231651  0.204527 -0.113531 -0.198096  0.177569  \n",
       "\n",
       "[50715 rows x 1728 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)\n",
    "data= torch.from_numpy(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50715, 1728])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40572, 1728])\n",
      "torch.Size([10143, 1728])\n"
     ]
    }
   ],
   "source": [
    "#将前80%作为训练集，后20%作为测试集\n",
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "vaild = data[train_size:]\n",
    "print(train.shape)\n",
    "print(vaild.shape)\n",
    "batch_size1 = 64\n",
    "w1 = 12\n",
    "w2 = 12\n",
    "w3 = 12\n",
    "\n",
    "train_data= TensorDataset(train)\n",
    "vaild_data= TensorDataset(vaild)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size = 64,\n",
    "                                           shuffle = True)\n",
    "\n",
    "vaild_loader = torch.utils.data.DataLoader(vaild_data,\n",
    "                                          batch_size = 64,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Fully connected (FC) block\n",
    "class FCB(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.bn = nn.BatchNorm1d(output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.fcb0 = FCB(input_size, 128, dropout)\n",
    "        self.fcb1 = FCB(128, 64, dropout)\n",
    "\n",
    "        self.fcb2 = FCB(64, 32, dropout)\n",
    "\n",
    "        self.fcb3 = FCB(32, 16, dropout)\n",
    "\n",
    "        self.fcb4 = FCB(16, 8, dropout)\n",
    "\n",
    "        self.fcb5 = FCB(8, 4, dropout)\n",
    "\n",
    "        self.fcb6 = FCB(4, 4, dropout)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = x.reshape(x.shape[0],1,x.shape[1])\n",
    "\n",
    "        x1 = self.fcb0(x)#x->128\n",
    "        x2 = self.fcb1(x1)\n",
    "\n",
    "        x3 = self.fcb2(x2)\n",
    "\n",
    "        x4 = self.fcb3(x3)\n",
    "\n",
    "        x5 = self.fcb4(x4)\n",
    "\n",
    "        x6 = self.fcb5(x5)\n",
    "\n",
    "        x7 = self.fcb6(x6)\n",
    "\n",
    "        x8 = self.fcb6(x7)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        return x2,x3,x4,x5,x6,x7,x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pab1 = FCB(8, 8, dropout)\n",
    "        self.pab2 = FCB(16, 16, dropout)\n",
    "        self.pab3 = FCB(32, 32, dropout)\n",
    "        self.pab4 = FCB(64, 64, dropout)\n",
    "        self.pab5 = FCB(128, 128, dropout)\n",
    "        self.pab6 = FCB(128, output_size, dropout)\n",
    "\n",
    "        self.activation = nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self,x2, x3,x4,x5,x6,x7,x8):\n",
    "        \n",
    "        x = torch.cat((x6,x8),dim=1)\n",
    "        x = self.pab1(x)\n",
    "        x = torch.cat((x,x5),dim=1)\n",
    "        x = self.pab2(x)\n",
    "        x = torch.cat((x,x4),dim=1)\n",
    "        x = self.pab3(x)\n",
    "        x = torch.cat((x,x3),dim=1)\n",
    "        x = self.pab4(x)\n",
    "        x = torch.cat((x,x2),dim=1)\n",
    "        x = self.pab5(x)\n",
    "        x = self.pab6(x)\n",
    "\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size)\n",
    "        self.decoder = Decoder(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2, x3,x4,x5,x6,x7,x8= self.encoder(x)\n",
    "        x = self.decoder(x2, x3,x4,x5,x6,x7,x8)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "model = AutoEncoder(w1*w2*w3,w1*w2*w3).to(device)\n",
    "#将模型转移到GPU上\n",
    "#criterion = MeanHuberLoss(delta=1.3)\n",
    "#criterion = WelschLoss(delta=0.5)\n",
    "#criterion = Loss0(delta=0.46,r=0.05)#0.5 and 0.2,SNR:-8dB ok\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.5753, Valid Loss: 0.2348\n",
      "loss_train:  [0.5752540377882377]\n",
      "vaild_train:  [0.23476196450632322]\n",
      "Epoch [2/100], Train Loss: 0.1475, Valid Loss: 0.0927\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841]\n",
      "Epoch [3/100], Train Loss: 0.0862, Valid Loss: 0.0831\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133]\n",
      "Epoch [4/100], Train Loss: 0.0822, Valid Loss: 0.0829\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653]\n",
      "Epoch [5/100], Train Loss: 0.0816, Valid Loss: 0.0825\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923]\n",
      "Epoch [6/100], Train Loss: 0.0811, Valid Loss: 0.0820\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263]\n",
      "Epoch [7/100], Train Loss: 0.0806, Valid Loss: 0.0816\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141]\n",
      "Epoch [8/100], Train Loss: 0.0802, Valid Loss: 0.0813\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775]\n",
      "Epoch [9/100], Train Loss: 0.0798, Valid Loss: 0.0810\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336]\n",
      "Epoch [10/100], Train Loss: 0.0795, Valid Loss: 0.0808\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955]\n",
      "Epoch [11/100], Train Loss: 0.0792, Valid Loss: 0.0806\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052]\n",
      "Epoch [12/100], Train Loss: 0.0791, Valid Loss: 0.0804\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242]\n",
      "Epoch [13/100], Train Loss: 0.0789, Valid Loss: 0.0804\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113]\n",
      "Epoch [14/100], Train Loss: 0.0788, Valid Loss: 0.0802\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008]\n",
      "Epoch [15/100], Train Loss: 0.0786, Valid Loss: 0.0802\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146]\n",
      "Epoch [16/100], Train Loss: 0.0785, Valid Loss: 0.0801\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495]\n",
      "Epoch [17/100], Train Loss: 0.0784, Valid Loss: 0.0800\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521]\n",
      "Epoch [18/100], Train Loss: 0.0783, Valid Loss: 0.0799\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616]\n",
      "Epoch [19/100], Train Loss: 0.0782, Valid Loss: 0.0799\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555]\n",
      "Epoch [20/100], Train Loss: 0.0782, Valid Loss: 0.0797\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064]\n",
      "Epoch [21/100], Train Loss: 0.0781, Valid Loss: 0.0797\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691]\n",
      "Epoch [22/100], Train Loss: 0.0780, Valid Loss: 0.0796\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192]\n",
      "Epoch [23/100], Train Loss: 0.0779, Valid Loss: 0.0796\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455]\n",
      "Epoch [24/100], Train Loss: 0.0779, Valid Loss: 0.0796\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668]\n",
      "Epoch [25/100], Train Loss: 0.0778, Valid Loss: 0.0796\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686]\n",
      "Epoch [26/100], Train Loss: 0.0778, Valid Loss: 0.0795\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589]\n",
      "Epoch [27/100], Train Loss: 0.0777, Valid Loss: 0.0795\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254]\n",
      "Epoch [28/100], Train Loss: 0.0777, Valid Loss: 0.0794\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783]\n",
      "Epoch [29/100], Train Loss: 0.0777, Valid Loss: 0.0794\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393]\n",
      "Epoch [30/100], Train Loss: 0.0777, Valid Loss: 0.0794\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828]\n",
      "Epoch [31/100], Train Loss: 0.0776, Valid Loss: 0.0794\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942]\n",
      "Epoch [32/100], Train Loss: 0.0776, Valid Loss: 0.0794\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066]\n",
      "Epoch [33/100], Train Loss: 0.0776, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877]\n",
      "Epoch [34/100], Train Loss: 0.0776, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132]\n",
      "Epoch [35/100], Train Loss: 0.0776, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742]\n",
      "Epoch [36/100], Train Loss: 0.0775, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208]\n",
      "Epoch [37/100], Train Loss: 0.0775, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504]\n",
      "Epoch [38/100], Train Loss: 0.0775, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732]\n",
      "Epoch [39/100], Train Loss: 0.0775, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856, 0.0774984335885251]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732, 0.07928566039545731]\n",
      "Epoch [40/100], Train Loss: 0.0775, Valid Loss: 0.0792\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856, 0.0774984335885251, 0.07747288306804861]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732, 0.07928566039545731, 0.07924463557747174]\n",
      "Epoch [41/100], Train Loss: 0.0775, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856, 0.0774984335885251, 0.07747288306804861, 0.07747025154413485]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732, 0.07928566039545731, 0.07924463557747174, 0.07929788548616493]\n",
      "Epoch [42/100], Train Loss: 0.0775, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856, 0.0774984335885251, 0.07747288306804861, 0.07747025154413485, 0.07747056437450628]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732, 0.07928566039545731, 0.07924463557747174, 0.07929788548616493, 0.07927922107888467]\n",
      "Epoch [43/100], Train Loss: 0.0774, Valid Loss: 0.0793\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856, 0.0774984335885251, 0.07747288306804861, 0.07747025154413485, 0.07747056437450628, 0.07743108603950555]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732, 0.07928566039545731, 0.07924463557747174, 0.07929788548616493, 0.07927922107888467, 0.07925283922901694]\n",
      "Epoch [44/100], Train Loss: 0.0774, Valid Loss: 0.0792\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856, 0.0774984335885251, 0.07747288306804861, 0.07747025154413485, 0.07747056437450628, 0.07743108603950555, 0.07743905328378692]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732, 0.07928566039545731, 0.07924463557747174, 0.07929788548616493, 0.07927922107888467, 0.07925283922901694, 0.0792020357348634]\n",
      "Epoch [45/100], Train Loss: 0.0774, Valid Loss: 0.0792\n",
      "loss_train:  [0.5752540377882377, 0.14746559881355484, 0.08618732833241814, 0.08220572183231827, 0.08163053188649262, 0.08108715331093747, 0.08063531704599548, 0.08021212087162662, 0.07982792541948779, 0.07949303568866727, 0.07923678159478711, 0.07907132884305358, 0.07889854924441889, 0.07876781671534201, 0.07864997693416824, 0.07849908119496488, 0.07840576727965652, 0.07830975510250507, 0.07824516357495581, 0.07816163889993252, 0.07806270043086555, 0.07801371564859472, 0.07794195762615098, 0.07787339383448336, 0.0778400361631947, 0.07778232407165626, 0.07771893168802517, 0.07771112443144765, 0.07765262436462501, 0.07765458283317202, 0.0776277207872281, 0.07760420946950793, 0.07757987151339603, 0.07755717051095015, 0.07755152177218383, 0.07753951368083713, 0.07753008296155027, 0.07748541367542856, 0.0774984335885251, 0.07747288306804861, 0.07747025154413485, 0.07747056437450628, 0.07743108603950555, 0.07743905328378692, 0.0774079237356547]\n",
      "vaild_train:  [0.23476196450632322, 0.0926899606326841, 0.08313200243239133, 0.08290299660754653, 0.08250586716633923, 0.0820103940911263, 0.08155094635374141, 0.08125563486004775, 0.08099462532397336, 0.08078972353312955, 0.08057334672355052, 0.08044028015069242, 0.08035989728926113, 0.08021128449425008, 0.08015846765641146, 0.08013437369709495, 0.08001261279455521, 0.07986433269842616, 0.07985491685147555, 0.07971998004231064, 0.07974287698853691, 0.0796274371773192, 0.07964306835483455, 0.07957951705785668, 0.0796022912803686, 0.07954716565286589, 0.07945598910252254, 0.0793930728386783, 0.0793788029150393, 0.07944776811314828, 0.07935059361112942, 0.07941521043485066, 0.07929927490229877, 0.07929745330563132, 0.07930029811536742, 0.07927089578138208, 0.07933464875948504, 0.07931743459131732, 0.07928566039545731, 0.07924463557747174, 0.07929788548616493, 0.07927922107888467, 0.07925283922901694, 0.0792020357348634, 0.07920147539497172]\n",
      "Epoch [46/100], Train Loss: 0.0774, Valid Loss: 0.0792\n",
      "Early stopped at epoch 45, train loss stop improving\n",
      "Training finished\n",
      "279.16053080558777\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "es_cnt = 0\n",
    "es_thres = 5\n",
    "prev_train_loss = float('inf')\n",
    "loss_train = []\n",
    "loss_vaild = []\n",
    "num_epochs = 100 # 总训练轮数\n",
    "#num_batch_train = 0\n",
    "for epoch in range(num_epochs):\n",
    "  #train_bar = tqdm(train_loader)\n",
    "  train_loss = 0.0\n",
    "  \n",
    "  for i , (batch) in enumerate(train_loader):\n",
    "\n",
    "    # 数据转到device\n",
    "    train_batch = batch[0].to(device)\n",
    "    \n",
    "    # 训练步骤  \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_batch)\n",
    "    loss = criterion(outputs, train_batch)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    #num_batch_train +=1\n",
    "  #train_loss除以所有bacth个数\n",
    "  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "  loss_train.append(train_loss)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  # 验证\n",
    "  valid_loss = 0.0\n",
    "  #num_batch_vaild = 0\n",
    "  with torch.no_grad():\n",
    "    for i , (batch) in enumerate(vaild_loader):\n",
    "    #for batch in vaild_loader:\n",
    "    \n",
    "      val_batch = batch[0].to(device)\n",
    "      \n",
    "      outputs = model(val_batch)\n",
    "      loss = criterion(outputs, val_batch)\n",
    "      valid_loss += loss.item()\n",
    "      #num_batch_vaild += 1\n",
    "    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "    loss_vaild.append(valid_loss)\n",
    "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "\n",
    "    \n",
    "    # Early stopping\n",
    "    if train_loss - prev_train_loss >= 0:\n",
    "        es_cnt += 1\n",
    "    else:\n",
    "        #es_cnt = 0\n",
    "        pass\n",
    "\n",
    "    if es_cnt >= es_thres:\n",
    "        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "        break  \n",
    "\n",
    "    prev_train_loss = train_loss\n",
    "  print('loss_train: ', loss_train)\n",
    "  print('vaild_train: ',loss_vaild)          \n",
    "print(\"Training finished\")\n",
    "current_time = time.time()\n",
    "time_sum = current_time-start_time\n",
    "print(time_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = pd.DataFrame(loss_train)\n",
    "loss_vaild = pd.DataFrame(loss_vaild)\n",
    "\n",
    "loss = pd.concat([loss_train,loss_vaild],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.columns = ['train_loss','vaild_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r'.\\model_3dsyn2patch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50715, 1728])\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(w1*w2*w3,w1*w2*w3).to(device)\n",
    "data = data.to(device)\n",
    "model.load_state_dict(torch.load(r'.\\model_3dsyn2patch.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "    #loss = criterion(output, data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.cpu()\n",
    "output = output.numpy()\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to_csv(r'loss_3dsyn2patch.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r'./output_3dsyn2patch.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_0 = []\n",
    "#start_time = time.time()\n",
    "#es_cnt = 0\n",
    "#es_thres = 5\n",
    "#prev_train_loss = float('inf')\n",
    "#loss_train = []\n",
    "#loss_vaild = []\n",
    "#num_epochs = 100 # 总训练轮数\n",
    "##num_batch_train = 0\n",
    "#for epoch in range(num_epochs):\n",
    "#  #train_bar = tqdm(train_loader)\n",
    "#  train_loss = 0.0\n",
    "#  \n",
    "#  for i , (batch) in enumerate(train_loader):\n",
    "#\n",
    "#    # 数据转到device\n",
    "#    train_batch = batch[0].to(device)\n",
    "#    \n",
    "#    # 训练步骤  \n",
    "#    optimizer.zero_grad()\n",
    "#    outputs = model(train_batch)\n",
    "#    loss = criterion(outputs, train_batch)\n",
    "#    loss.backward() \n",
    "#    optimizer.step()\n",
    "#\n",
    "#    loss_0.append(loss.item())\n",
    "#\n",
    "#    train_loss += loss.item()\n",
    "#    #num_batch_train +=1\n",
    "#  #train_loss除以所有bacth个数\n",
    "#  train_loss = train_loss/(np.ceil(train.size(0)/batch_size1))\n",
    "#  loss_train.append(train_loss)\n",
    "#    \n",
    "#\n",
    "#\n",
    "#\n",
    "#  # 验证\n",
    "#  valid_loss = 0.0\n",
    "#  #num_batch_vaild = 0\n",
    "#  with torch.no_grad():\n",
    "#    for i , (batch) in enumerate(vaild_loader):\n",
    "#    #for batch in vaild_loader:\n",
    "#    \n",
    "#      val_batch = batch[0].to(device)\n",
    "#      \n",
    "#      outputs = model(val_batch)\n",
    "#      loss = criterion(outputs, val_batch)\n",
    "#      valid_loss += loss.item()\n",
    "#      #num_batch_vaild += 1\n",
    "#    valid_loss = valid_loss/(np.ceil(vaild.size(0)/batch_size1))\n",
    "#    loss_vaild.append(valid_loss)\n",
    "#    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, valid_loss))\n",
    "#\n",
    "#    \n",
    "#    # Early stopping\n",
    "#    if train_loss - prev_train_loss >= 0:\n",
    "#        es_cnt += 1\n",
    "#    else:\n",
    "#        #es_cnt = 0\n",
    "#        pass\n",
    "#\n",
    "#    if es_cnt >= es_thres:\n",
    "#        print(f\"Early stopped at epoch {epoch}, train loss stop improving\")\n",
    "#        break  \n",
    "#    \n",
    "#\n",
    "#\n",
    "##   if epoch == 10:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs10.pth')\n",
    "##   elif epoch == 20:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs20.pth')\n",
    "##   elif epoch == 30:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs30.pth')\n",
    "##   elif epoch == 40:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs40.pth')\n",
    "##   elif epoch == 50:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs50.pth')\n",
    "##   elif epoch == 60:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs60.pth')\n",
    "##   elif epoch == 70:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs70.pth')\n",
    "##   elif epoch == 80:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs80.pth')\n",
    "##   elif epoch == 90:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs90.pth')\n",
    "##   elif epoch == 100:\n",
    "##     torch.save(model.state_dict(), r'.\\model_epochs100.pth')\n",
    "##   else:\n",
    "##       pass\n",
    "#\n",
    "#    prev_train_loss = train_loss\n",
    "#  print('loss_train: ', loss_train)\n",
    "#  print('vaild_train: ',loss_vaild)          \n",
    "#print(\"Training finished\")\n",
    "#current_time = time.time()\n",
    "#time_sum = current_time-start_time\n",
    "#print(time_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
